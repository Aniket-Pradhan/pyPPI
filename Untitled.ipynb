{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script runs classifier training over the entire training data and then\n",
    "output predictions over the interactome.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pyPPI.base import parse_args, su_make_dir\n",
    "from pyPPI.data import load_network_from_path, load_ptm_labels\n",
    "from pyPPI.data import testing_network_path, training_network_path\n",
    "\n",
    "from pyPPI.models import make_classifier\n",
    "from pyPPI.model_selection.scoring import MultilabelScorer, Statistics\n",
    "from pyPPI.model_selection.experiment import KFoldExperiment, Bootstrap\n",
    "from pyPPI.model_selection.sampling import IterativeStratifiedKFold\n",
    "\n",
    "from pyPPI.data_mining.features import AnnotationExtractor\n",
    "from pyPPI.data_mining.uniprot import UniProt, get_active_instance\n",
    "from pyPPI.data_mining.tools import xy_from_interaction_frame\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, label_ranking_average_precision_score\n",
    "from sklearn.metrics import recall_score, make_scorer, label_ranking_loss, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from skmultilearn.problem_transform.br import BinaryRelevance\n",
    "from skmultilearn.problem_transform.cc import ClassifierChain\n",
    "\n",
    "n_jobs=3\n",
    "n_splits=5\n",
    "n_iterations=1\n",
    "induce=True\n",
    "verbose=True\n",
    "model = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data labels...\n",
      "Loading feature data...\n",
      "First time loading on UniProt instance. Make take a few moments\n",
      "Warning: Loading dat files, may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data labels...\")\n",
    "labels = load_ptm_labels()\n",
    "\n",
    "print(\"Loading feature data...\")\n",
    "uniprot = get_active_instance(verbose=verbose)\n",
    "data_types = UniProt.data_types()\n",
    "selection = [\n",
    "    data_types.GO_MF.value,\n",
    "    data_types.GO_BP.value,\n",
    "    data_types.GO_CC.value,\n",
    "    data_types.INTERPRO.value,\n",
    "    data_types.PFAM.value\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the features from protein annotation selection...\n"
     ]
    }
   ],
   "source": [
    "# Build the features from protein annotation selection.\n",
    "print('Building the features from protein annotation selection...')\n",
    "annotation_ex = AnnotationExtractor(\n",
    "    induce=induce,\n",
    "    selection=selection,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    "    cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training and testing data...\n",
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n",
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing training and testing data...\")\n",
    "training = load_network_from_path(training_network_path)\n",
    "testing = load_network_from_path(testing_network_path)\n",
    "mlb = MultiLabelBinarizer(classes=labels, sparse_output=True)\n",
    "\n",
    "X_dev_ppis, y_dev = xy_from_interaction_frame(training)\n",
    "X_test_ppis, y_test = xy_from_interaction_frame(testing)\n",
    "mlb.fit(y_dev)\n",
    "\n",
    "X_dev = annotation_ex.transform(X_dev_ppis)\n",
    "y_dev = mlb.transform(y_dev)\n",
    "\n",
    "X_test = annotation_ex.transform(X_test_ppis)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up scorers...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up scorers...\")\n",
    "f1_scorer = MultilabelScorer(f1_score)\n",
    "recall_scorer = MultilabelScorer(recall_score)\n",
    "precision_scorer = MultilabelScorer(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up experiments...\n",
      "Fitting iteration 1\n",
      "\tFitting split 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py:438: UserWarning: Failed to clean temporary folder: C:\\Users\\Daniel\\AppData\\Local\\Temp\\joblib_memmaping_pool_416_2017895208496\n",
      "  warnings.warn(\"Failed to clean temporary folder: %s\" % folder_path)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 232, in _fit_and_score\n    X_test, y_test = _safe_split(estimator, X, y, test, train)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 108, in _safe_split\n    X_subset = safe_indexing(X, indices)\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\__init__.py\", line 110, in safe_indexing\n    return X.take(indices, axis=0)\nMemoryError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nMemoryError                                        Mon Jun 26 00:09:44 2017\nPID: 3592      Python 3.5.3: C:\\ProgramData\\Anaconda3\\envs\\pyppi\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), array([0, 0, 0, ..., 0, 0, 0]), make_scorer(f1_score), array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), array([   0,    1,    2, ..., 6820, 6821, 8615]), 0, {'C': 20.000000000000004, 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), array([0, 0, 0, ..., 0, 0, 0]), make_scorer(f1_score), array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), array([   0,    1,    2, ..., 6820, 6821, 8615]), 0, {'C': 20.000000000000004, 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=make_scorer(f1_score), train=array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), test=array([   0,    1,    2, ..., 6820, 6821, 8615]), verbose=0, parameters={'C': 20.000000000000004, 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n--> 232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n        X_test = undefined\n        y_test = undefined\n        estimator = LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False)\n        X = memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n        y = array([0, 0, 0, ..., 0, 0, 0])\n        test = array([   0,    1,    2, ..., 6820, 6821, 8615])\n        train = array([ 6822,  6823,  6824, ..., 20462, 20463, 20464])\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _safe_split(estimator=LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), y=array([0, 0, 0, ..., 0, 0, 0]), indices=array([   0,    1,    2, ..., 6820, 6821, 8615]), train_indices=array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]))\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n        indices = array([   0,    1,    2, ..., 6820, 6821, 8615])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\__init__.py in safe_indexing(X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), indices=array([   0,    1,    2, ..., 6820, 6821, 8615]))\n    105             return X.copy().iloc[indices]\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n--> 110             return X.take(indices, axis=0)\n        X.take = <built-in method take of memmap object>\n        indices = array([   0,    1,    2, ..., 6820, 6821, 8615])\n    111         else:\n    112             return X[indices]\n    113     else:\n    114         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nMemoryError                                        Mon Jun 26 00:09:44 2017\nPID: 3592      Python 3.5.3: C:\\ProgramData\\Anaconda3\\envs\\pyppi\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), array([0, 0, 0, ..., 0, 0, 0]), make_scorer(f1_score), array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), array([   0,    1,    2, ..., 6820, 6821, 8615]), 0, {'C': 20.000000000000004, 'penalty': 'l1'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), array([0, 0, 0, ..., 0, 0, 0]), make_scorer(f1_score), array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), array([   0,    1,    2, ..., 6820, 6821, 8615]), 0, {'C': 20.000000000000004, 'penalty': 'l1'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), y=array([0, 0, 0, ..., 0, 0, 0]), scorer=make_scorer(f1_score), train=array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]), test=array([   0,    1,    2, ..., 6820, 6821, 8615]), verbose=0, parameters={'C': 20.000000000000004, 'penalty': 'l1'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    227         estimator.set_params(**parameters)\n    228 \n    229     start_time = time.time()\n    230 \n    231     X_train, y_train = _safe_split(estimator, X, y, train)\n--> 232     X_test, y_test = _safe_split(estimator, X, y, test, train)\n        X_test = undefined\n        y_test = undefined\n        estimator = LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False)\n        X = memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n        y = array([0, 0, 0, ..., 0, 0, 0])\n        test = array([   0,    1,    2, ..., 6820, 6821, 8615])\n        train = array([ 6822,  6823,  6824, ..., 20462, 20463, 20464])\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _safe_split(estimator=LogisticRegression(C=20.000000000000004, class_w...linear', tol=0.0001, verbose=0, warm_start=False), X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), y=array([0, 0, 0, ..., 0, 0, 0]), indices=array([   0,    1,    2, ..., 6820, 6821, 8615]), train_indices=array([ 6822,  6823,  6824, ..., 20462, 20463, 20464]))\n    103             if train_indices is None:\n    104                 X_subset = X[np.ix_(indices, indices)]\n    105             else:\n    106                 X_subset = X[np.ix_(indices, train_indices)]\n    107         else:\n--> 108             X_subset = safe_indexing(X, indices)\n        X_subset = undefined\n        X = memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)\n        indices = array([   0,    1,    2, ..., 6820, 6821, 8615])\n    109 \n    110     if y is not None:\n    111         y_subset = safe_indexing(y, indices)\n    112     else:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\utils\\__init__.py in safe_indexing(X=memmap([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0...0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=int64), indices=array([   0,    1,    2, ..., 6820, 6821, 8615]))\n    105             return X.copy().iloc[indices]\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n--> 110             return X.take(indices, axis=0)\n        X.take = <built-in method take of memmap object>\n        indices = array([   0,    1,    2, ..., 6820, 6821, 8615])\n    111         else:\n    112             return X[indices]\n    113     else:\n    114         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-bf40f8061459>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mX_train_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0my_train_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_j\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_j\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mX_test_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Daniel\\AppData\\Roaming\\Python\\Python35\\site-packages\\scikit_multilearn-0.0.5-py3.5.egg\\skmultilearn\\problem_transform\\br.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0my_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_data_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             classifier.fit(self.ensure_input_format(\n\u001b[1;32m---> 71\u001b[1;33m                 X), self.ensure_output_format(y_subset))\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m--> 564\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    716\u001b[0m                     \u001b[1;31m# scheduling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 718\u001b[1;33m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    719\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;34m\"\"\"Shutdown the pool and restart a new one with the same parameters\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             self.configure(n_jobs=self.parallel.n_jobs, parallel=self.parallel,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;34m\"\"\"Shutdown the process or thread pool\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMultiprocessingBackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJOBLIB_SPAWNED_PROCESS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# terminate does a join()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\sklearn\\externals\\joblib\\pool.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_retries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                 \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMemmapingPool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mWindowsError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\util.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, wr, _finalizer_registry, sub_debug, getpid)\u001b[0m\n\u001b[0;32m    184\u001b[0m                 sub_debug('finalizer calling %s with args %s and kwargs %s',\n\u001b[0;32m    185\u001b[0m                           self._callback, self._args, self._kwargs)\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weakref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_terminate_pool\u001b[1;34m(cls, taskqueue, inqueue, outqueue, pool, worker_handler, task_handler, result_handler, cache)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'helping task handler/workers to finish'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_help_stuff_finish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minqueue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36m_help_stuff_finish\u001b[1;34m(inqueue, task_handler, size)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# task_handler may be blocked trying to put items on inqueue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'removing tasks from inqueue until task handler finished'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[0minqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mtask_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0minqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Setting up experiments...\")\n",
    "cv_seeds = range(1, n_splits + 1)\n",
    "clf_seeds = range(1, n_iterations * n_splits + 1)\n",
    "clf_seeds = np.asarray(seeds).reshape(n_iterations, n_splits)\n",
    "\n",
    "binary_score_data = np.zeros((n_iterations, n_splits, 3, len(mlb.classes)))\n",
    "mlb_score_data = np.zeros((n_iterations, n_splits, 4, 1))\n",
    "\n",
    "binary_score_data_hold_out = np.zeros((n_iterations, n_splits, 3, len(mlb.classes)))\n",
    "mlb_score_data_hold_out = np.zeros((n_iterations, n_splits, 4, 1))\n",
    "\n",
    "binary_scoring_funcs = [\n",
    "    ('Binary F1', f1_scorer) , \n",
    "    ('Precision', precision_scorer), \n",
    "    ('Recall', recall_scorer)\n",
    "]\n",
    "mlb_scores_funcs = [\n",
    "    ('Label Ranking Loss', label_ranking_loss), \n",
    "    ('Label Ranking Average Precision', label_ranking_average_precision_score), \n",
    "    ('Macro (weighted) F1', f1_score), \n",
    "    ('Macro (un-weighted) F1', f1_score)\n",
    "]\n",
    "param_distribution = {\n",
    "    'C': np.arange(0.1, 20.1, step=0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "for iter_j in range(n_iterations):\n",
    "    print(\"Fitting iteration {}\".format(iter_j + 1))\n",
    "    cv = IterativeStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=cv_seeds[iter_j])\n",
    "    for split_i, (train_idx, test_idx) in enumerate(cv.split(X_dev, y_dev.toarray())):\n",
    "        print(\"\\tFitting split {}\".format(split_i + 1))\n",
    "        random_cv = RandomizedSearchCV(\n",
    "            cv=3,\n",
    "            n_jobs=n_jobs,\n",
    "            n_iter=60,\n",
    "            random_state=clf_seeds[iter_j, split_i],\n",
    "            param_distributions=param_distribution,\n",
    "            estimator=make_classifier(model, random_state=clf_seeds[iter_j, split_i]),\n",
    "            scoring=make_scorer(f1_score, greater_is_better=True)\n",
    "        )\n",
    "        clf = BinaryRelevance(random_cv)\n",
    "        \n",
    "        vectorizer = CountVectorizer(binary=False)\n",
    "        X_train_j = vectorizer.fit_transform(X_dev[train_idx, ])\n",
    "        y_train_j = y_dev[train_idx, ]        \n",
    "        clf.fit(X_train_j, y_train_j)\n",
    "        \n",
    "        X_test_j = vectorizer.transform(X_dev[test_idx, ])\n",
    "        y_true_j = y_dev[test_idx, ].toarray()\n",
    "        y_pred_j = clf.predict(X_test_j).toarray()\n",
    "        y_proba_j = clf.predict_proba(X_test_j).toarray()\n",
    "        \n",
    "        X_hold_out = vectorizer.transform(X_test)\n",
    "        y_pred_hold_out = clf.predict(X_hold_out).toarray()\n",
    "        y_proba_hold_out = clf.predict_proba(X_hold_out).toarray()\n",
    "        y_true_hold_out = y_test.toarray()\n",
    "        \n",
    "        for func_idx, (_, func) in enumerate(binary_scoring_funcs):\n",
    "            scores_v = func(y_true_j, y_pred_j, average='binary')\n",
    "            binary_score_data[iter_j, split_i, func_idx, :] = scores_v\n",
    "            \n",
    "            scores_h = func(y_true_hold_out, y_pred_hold_out, average='binary')\n",
    "            binary_score_data_hold_out[iter_j, split_i, func_idx, :] = scores_h\n",
    "        \n",
    "        for func_idx, (func_name, func) in enumerate(mlb_scores_funcs):\n",
    "            if func_name == 'Macro (weighted) F1':\n",
    "                scores_v = func(y_true_j, y_pred_j, average='weighted')\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out, average='weighted')\n",
    "            elif func_name == 'Macro (un-weighted) F1':\n",
    "                scores_v = func(y_true_j, y_pred_j, average='macro')\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out, average='macro')\n",
    "            elif func_name == 'Label Ranking Average Precision':\n",
    "                scores_v = func(y_true_j, y_proba_j)\n",
    "                scores_h = func(y_true_hold_out, y_proba_hold_out)\n",
    "            else:\n",
    "                scores_v = func(y_true_j, y_pred_j)\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out)\n",
    "            \n",
    "            mlb_score_data[iter_j, split_i, func_idx, 0] = scores_v\n",
    "            mlb_score_data_hold_out[iter_j, split_i, func_idx, 0] = scores_h          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
