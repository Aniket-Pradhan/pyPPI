{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load obo file /Users/daniel/Git/pyPPI/pyPPI/data/gene_ontology.1_2.obo\n",
      "/Users/daniel/Git/pyPPI/pyPPI/data/gene_ontology.1_2.obo: fmt(1.2) rel(2016-08-05) 47,019 GO Terms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script runs classifier training over the entire training data and then\n",
    "output predictions over the interactome.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from pyPPI.base import parse_args, su_make_dir\n",
    "from pyPPI.data import load_network_from_path, load_ptm_labels\n",
    "from pyPPI.data import testing_network_path, training_network_path\n",
    "\n",
    "from pyPPI.models import make_classifier\n",
    "from pyPPI.model_selection.scoring import MultilabelScorer, Statistics\n",
    "from pyPPI.model_selection.experiment import KFoldExperiment, Bootstrap\n",
    "from pyPPI.model_selection.sampling import IterativeStratifiedKFold\n",
    "\n",
    "from pyPPI.data_mining.features import AnnotationExtractor\n",
    "from pyPPI.data_mining.uniprot import UniProt, get_active_instance\n",
    "from pyPPI.data_mining.tools import xy_from_interaction_frame\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, label_ranking_average_precision_score\n",
    "from sklearn.metrics import recall_score, make_scorer, label_ranking_loss, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from skmultilearn.problem_transform.br import BinaryRelevance\n",
    "from skmultilearn.problem_transform.cc import ClassifierChain\n",
    "\n",
    "n_jobs=3\n",
    "n_splits=5\n",
    "n_iterations=1\n",
    "induce=True\n",
    "verbose=True\n",
    "model = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data labels...\n",
      "Loading feature data...\n",
      "First time loading on UniProt instance. Make take a few moments\n",
      "Warning: Loading dat files, may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data labels...\")\n",
    "labels = load_ptm_labels()\n",
    "\n",
    "print(\"Loading feature data...\")\n",
    "uniprot = get_active_instance(verbose=verbose)\n",
    "data_types = UniProt.data_types()\n",
    "selection = [\n",
    "    data_types.GO_MF.value,\n",
    "    data_types.GO_BP.value,\n",
    "    data_types.GO_CC.value,\n",
    "    data_types.INTERPRO.value,\n",
    "    data_types.PFAM.value\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the features from protein annotation selection...\n"
     ]
    }
   ],
   "source": [
    "# Build the features from protein annotation selection.\n",
    "print('Building the features from protein annotation selection...')\n",
    "annotation_ex = AnnotationExtractor(\n",
    "    induce=induce,\n",
    "    selection=selection,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    "    cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training and testing data...\n",
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n",
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing training and testing data...\")\n",
    "training = load_network_from_path(training_network_path)\n",
    "testing = load_network_from_path(testing_network_path)\n",
    "mlb = MultiLabelBinarizer(classes=labels, sparse_output=True)\n",
    "\n",
    "X_dev_ppis, y_dev = xy_from_interaction_frame(training)\n",
    "X_test_ppis, y_test = xy_from_interaction_frame(testing)\n",
    "mlb.fit(y_dev)\n",
    "\n",
    "X_dev = annotation_ex.transform(X_dev_ppis)\n",
    "y_dev = mlb.transform(y_dev)\n",
    "\n",
    "X_test = annotation_ex.transform(X_test_ppis)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up scorers...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up scorers...\")\n",
    "f1_scorer = MultilabelScorer(f1_score)\n",
    "recall_scorer = MultilabelScorer(recall_score)\n",
    "precision_scorer = MultilabelScorer(precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up experiments...\n",
      "Fitting iteration 1\n",
      "\tFitting split 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up experiments...\")\n",
    "cv_seeds = range(1, n_splits + 1)\n",
    "clf_seeds = range(1, n_iterations * n_splits + 1)\n",
    "clf_seeds = np.asarray(clf_seeds).reshape(n_iterations, n_splits)\n",
    "\n",
    "binary_score_data = np.zeros((n_iterations, n_splits, 3, len(mlb.classes)))\n",
    "mlb_score_data = np.zeros((n_iterations, n_splits, 4, 1))\n",
    "\n",
    "binary_score_data_hold_out = np.zeros((n_iterations, n_splits, 3, len(mlb.classes)))\n",
    "mlb_score_data_hold_out = np.zeros((n_iterations, n_splits, 4, 1))\n",
    "\n",
    "binary_scoring_funcs = [\n",
    "    ('Binary F1', f1_scorer) , \n",
    "    ('Precision', precision_scorer), \n",
    "    ('Recall', recall_scorer)\n",
    "]\n",
    "mlb_scores_funcs = [\n",
    "    ('Label Ranking Loss', label_ranking_loss), \n",
    "    ('Label Ranking Average Precision', label_ranking_average_precision_score), \n",
    "    ('Macro (weighted) F1', f1_score), \n",
    "    ('Macro (un-weighted) F1', f1_score)\n",
    "]\n",
    "param_distribution = {\n",
    "    'C': np.arange(0.1, 20.1, step=0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "for iter_j in range(n_iterations):\n",
    "    print(\"Fitting iteration {}\".format(iter_j + 1))\n",
    "    cv = IterativeStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=cv_seeds[iter_j])\n",
    "    for split_i, (train_idx, test_idx) in enumerate(cv.split(X_dev, y_dev.toarray())):\n",
    "        print(\"\\tFitting split {}\".format(split_i + 1))\n",
    "        random_cv = RandomizedSearchCV(\n",
    "            cv=3,\n",
    "            n_jobs=n_jobs,\n",
    "            n_iter=60,\n",
    "            random_state=clf_seeds[iter_j, split_i],\n",
    "            param_distributions=param_distribution,\n",
    "            estimator=make_classifier(model, random_state=clf_seeds[iter_j, split_i]),\n",
    "            scoring=make_scorer(f1_score, greater_is_better=True)\n",
    "        )\n",
    "        clf = BinaryRelevance(random_cv)\n",
    "        \n",
    "        vectorizer = CountVectorizer(binary=False)\n",
    "        X_train_j = vectorizer.fit_transform(X_dev[train_idx, ])\n",
    "        y_train_j = y_dev[train_idx, ]        \n",
    "        clf.fit(X_train_j, y_train_j)\n",
    "        \n",
    "        X_test_j = vectorizer.transform(X_dev[test_idx, ])\n",
    "        y_true_j = y_dev[test_idx, ].toarray()\n",
    "        y_pred_j = clf.predict(X_test_j).toarray()\n",
    "        y_proba_j = clf.predict_proba(X_test_j).toarray()\n",
    "        \n",
    "        X_hold_out = vectorizer.transform(X_test)\n",
    "        y_pred_hold_out = clf.predict(X_hold_out).toarray()\n",
    "        y_proba_hold_out = clf.predict_proba(X_hold_out).toarray()\n",
    "        y_true_hold_out = y_test.toarray()\n",
    "        \n",
    "        for func_idx, (_, func) in enumerate(binary_scoring_funcs):\n",
    "            scores_v = func(y_true_j, y_pred_j, average='binary')\n",
    "            binary_score_data[iter_j, split_i, func_idx, :] = scores_v\n",
    "            \n",
    "            scores_h = func(y_true_hold_out, y_pred_hold_out, average='binary')\n",
    "            binary_score_data_hold_out[iter_j, split_i, func_idx, :] = scores_h\n",
    "        \n",
    "        for func_idx, (func_name, func) in enumerate(mlb_scores_funcs):\n",
    "            if func_name == 'Macro (weighted) F1':\n",
    "                scores_v = func(y_true_j, y_pred_j, average='weighted')\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out, average='weighted')\n",
    "            elif func_name == 'Macro (un-weighted) F1':\n",
    "                scores_v = func(y_true_j, y_pred_j, average='macro')\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out, average='macro')\n",
    "            elif func_name == 'Label Ranking Average Precision':\n",
    "                scores_v = func(y_true_j, y_proba_j)\n",
    "                scores_h = func(y_true_hold_out, y_proba_hold_out)\n",
    "            else:\n",
    "                scores_v = func(y_true_j, y_pred_j)\n",
    "                scores_h = func(y_true_hold_out, y_pred_hold_out)\n",
    "            \n",
    "            mlb_score_data[iter_j, split_i, func_idx, 0] = scores_v\n",
    "            mlb_score_data_hold_out[iter_j, split_i, func_idx, 0] = scores_h          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
