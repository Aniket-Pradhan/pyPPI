{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script runs the bootstrap kfold validation experiments as used in\n",
    "the publication.\n",
    "\n",
    "Usage:\n",
    "  validation.py [--interpro] [--pfam] [--mf] [--cc] [--bp]\n",
    "             [--use_cache] [--induce] [--verbose] [--abs] [--top=T]\n",
    "             [--model=M] [--n_jobs=J] [--n_splits=S] [--n_iterations=I]\n",
    "             [--h_iterations=H] [--directory=DIR]\n",
    "  validation.py -h | --help\n",
    "\n",
    "Options:\n",
    "  -h --help     Show this screen.\n",
    "  --interpro    Use interpro domains in features.\n",
    "  --pfam        Use Pfam domains in features.\n",
    "  --mf          Use Molecular Function Gene Ontology in features.\n",
    "  --cc          Use Cellular Compartment Gene Ontology in features.\n",
    "  --bp          Use Biological Process Gene Ontology in features.\n",
    "  --binary      Use binary feature encoding instead of ternary.\n",
    "  --induce      Use ULCA inducer over Gene Ontology.\n",
    "  --verbose     Print intermediate output for debugging.\n",
    "  --use_cache   Use cached features if available.\n",
    "  --abs         Take the absolute value of feature weights when computing top\n",
    "                features.\n",
    "  --top=T       Top T features for each label to log [default: 25]\n",
    "  --model=M         A binary classifier from Scikit-Learn implementing fit,\n",
    "                    predict and predict_proba [default: LogisticRegression]\n",
    "  --n_jobs=J        Number of processes to run in parallel [default: 1]\n",
    "  --n_splits=S      Number of cross-validation splits [default: 5]\n",
    "  --h_iterations=H  Number of hyperparameter tuning\n",
    "                    iterations per fold [default: 60]\n",
    "  --n_iterations=I  Number of bootstrap iterations [default: 5]\n",
    "  --directory=DIR   Output directory [default: ./results/]\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from itertools import product\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from docopt import docopt\n",
    "\n",
    "from pyppi.base import parse_args, su_make_dir\n",
    "from pyppi.data import load_network_from_path, load_ptm_labels\n",
    "from pyppi.data import testing_network_path, training_network_path\n",
    "from pyppi.data import get_term_description, ipr_name_map, pfam_name_map\n",
    "\n",
    "from pyppi.models.binary_relevance import get_coefs, top_n_features\n",
    "from pyppi.models import make_classifier, get_parameter_distribution_for_model\n",
    "from pyppi.models import supported_estimators\n",
    "from pyppi.model_selection.scoring import fdr_score, specificity\n",
    "from pyppi.model_selection.sampling import IterativeStratifiedKFold\n",
    "\n",
    "from pyppi.data_mining.features import AnnotationExtractor\n",
    "from pyppi.data_mining.uniprot import UniProt, get_active_instance\n",
    "from pyppi.data_mining.tools import xy_from_interaction_frame\n",
    "from pyppi.data_mining.ontology import get_active_instance as load_godag\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import (\n",
    "    recall_score, make_scorer,\n",
    "    label_ranking_average_precision_score,\n",
    "    label_ranking_loss,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "logging.captureWarnings(False)\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s',\n",
    "    datefmt='%m-%d-%Y %I:%M:%S',\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "args = {\n",
    "    'n_jobs': 6,\n",
    "    'n_splits': 2,\n",
    "    'n_iterations': 2,\n",
    "    'h_iterations': 3,\n",
    "    'induce': True,\n",
    "    'verbose': True,\n",
    "    'use_binary': False,\n",
    "    'abs': True,\n",
    "    'top': 25,\n",
    "    'selection': [\n",
    "        UniProt.data_types().GO_MF.value,\n",
    "        UniProt.data_types().GO_BP.value,\n",
    "        UniProt.data_types().GO_CC.value,\n",
    "        UniProt.data_types().INTERPRO.value,\n",
    "        UniProt.data_types().PFAM.value\n",
    "    ],\n",
    "    'model': 'LogisticRegression',\n",
    "    'use_cache': True,\n",
    "    'directory': './results/'\n",
    "}\n",
    "n_jobs = args['n_jobs']\n",
    "n_splits = args['n_splits']\n",
    "n_iter = args['n_iterations']\n",
    "induce = args['induce']\n",
    "verbose = args['verbose']\n",
    "selection = args['selection']\n",
    "model = args['model']\n",
    "use_feature_cache = args['use_cache']\n",
    "direc = args['directory']\n",
    "hyperparam_iter = args['h_iterations']\n",
    "get_top_n = args['top']\n",
    "abs_weights = args['abs']\n",
    "use_binary = args['use_binary']\n",
    "\n",
    "\n",
    "# Set up the folder for each experiment run named after the current time\n",
    "folder = datetime.now().strftime(\"val_%y-%m-%d_%H-%M\")\n",
    "direc = \"{}/{}/\".format(direc, folder)\n",
    "su_make_dir(direc)\n",
    "json.dump(\n",
    "    args, fp=open(\"{}/settings.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:12:21] INFO: Loading training and testing data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time loading on GO-DAG instance. Make take a few moments\n",
      "load obo file /Users/daniel/.pyppi/go.obo\n",
      "/Users/daniel/.pyppi/go.obo: fmt(1.2) rel(2017-07-14) 48,971 GO Terms\n",
      "First time loading on UniProt instance. Make take a few moments\n",
      "Warning: Loading dat files, may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "# Load all the training data, features etc.\n",
    "# ------------------------------------------------------------------- #\n",
    "logging.info(\"Loading training and testing data.\")\n",
    "ipr_map = ipr_name_map(short_names=False)\n",
    "pfam_map = pfam_name_map()\n",
    "go_dag = load_godag()\n",
    "uniprot = get_active_instance(\n",
    "    verbose=verbose,\n",
    "    sprot_cache=False if use_feature_cache else True,\n",
    "    trembl_cache=False if use_feature_cache else True\n",
    ")\n",
    "data_types = UniProt.data_types()\n",
    "labels = load_ptm_labels()\n",
    "annotation_ex = AnnotationExtractor(\n",
    "    induce=induce,\n",
    "    selection=selection,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    "    cache=use_feature_cache,\n",
    "    backend='threading'\n",
    ")\n",
    "training = load_network_from_path(training_network_path)\n",
    "testing = load_network_from_path(testing_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:12:59] INFO: Preparing training and testing data.\n",
      "[11-20-2017 07:13:00] INFO: Computing class distributions.\n"
     ]
    }
   ],
   "source": [
    "# Get the features into X, and multilabel y indicator format\n",
    "# -------------------------------------------------------------------- #\n",
    "logging.info(\"Preparing training and testing data.\")\n",
    "mlb = MultiLabelBinarizer(classes=labels, sparse_output=False)\n",
    "X_train_ppis, y_train = xy_from_interaction_frame(training)\n",
    "X_test_ppis, y_test = xy_from_interaction_frame(testing)\n",
    "mlb.fit(y_train)\n",
    "\n",
    "logging.info(\"Computing class distributions.\")\n",
    "json.dump(\n",
    "    Counter([l for ls in y_train for l in ls]),\n",
    "    fp=open(\"{}/training_distribution.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True\n",
    ")\n",
    "json.dump(\n",
    "    Counter([l for ls in y_test for l in ls]),\n",
    "    fp=open(\"{}/testing_distribution.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True\n",
    ")\n",
    "\n",
    "X_train = annotation_ex.transform(X_train_ppis)\n",
    "X_test = annotation_ex.transform(X_test_ppis)\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These take up around ~5GB so it's best to delete them from memory\n",
    "# -------------------------------------------------------------------- #\n",
    "del annotation_ex\n",
    "del uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:13:13] INFO: Setting up preliminaries and the statistics arrays\n",
      "[11-20-2017 07:13:13] INFO: Found classes carboxylation, acetylation, sumoylation, glycosylation, sulfation, dissociation, activation, prenylation, dephosphorylation, myristoylation, methylation, inhibition, deacetylation, ubiquitination, state-change, proteolytic-cleavage, phosphorylation, binding/association\n"
     ]
    }
   ],
   "source": [
    "# Set up the numpy arrays and dictionarys for statistics etc\n",
    "# -------------------------------------------------------------------- #\n",
    "logging.info(\"Setting up preliminaries and the statistics arrays\")\n",
    "logging.info(\"Found classes {}\".format(', '.join(mlb.classes)))\n",
    "n_classes = len(mlb.classes)\n",
    "seeds = range(n_iter)\n",
    "top_features = {\n",
    "    l: {\n",
    "        i: {\n",
    "            j: [] for j in range(n_splits)\n",
    "        } for i in range(n_iter)\n",
    "    } for l in mlb.classes\n",
    "}\n",
    "params = get_parameter_distribution_for_model(model)\n",
    "\n",
    "binary_scoring_funcs = [\n",
    "    ('Binary F1', f1_score),\n",
    "    ('Precision', precision_score),\n",
    "    ('Recall', recall_score),\n",
    "    ('Specificity', specificity),\n",
    "    ('FDR', fdr_score)\n",
    "]\n",
    "multilabel_scoring_funcs = [\n",
    "    ('Label Ranking Loss', label_ranking_loss),\n",
    "    ('Label Ranking Average Precision',\n",
    "        label_ranking_average_precision_score),\n",
    "    ('Macro (weighted) F1', f1_score),\n",
    "    ('Macro (un-weighted) F1', f1_score)\n",
    "]\n",
    "n_scorers = len(binary_scoring_funcs)\n",
    "n_ml_scorers = len(multilabel_scoring_funcs)\n",
    "\n",
    "# 2: position 0 is for validation, position 1 is for testing\n",
    "binary_statistics = np.zeros((n_classes, 2, n_scorers, n_iter, n_splits))\n",
    "multilabel_statistics = np.zeros((2, n_ml_scorers, n_iter, n_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:13:14] INFO: Fitting bootstrap iteration 1.\n",
      "[11-20-2017 07:13:17] INFO: Fitting fold iteration 1.\n",
      "[11-20-2017 07:13:17] INFO: Fitting label carboxylation.\n",
      "[11-20-2017 07:13:17] INFO: Preparing data.\n",
      "[11-20-2017 07:13:25] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[11-20-2017 07:13:32] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:13:32] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:13:32] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:13:32] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:13:32] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:13:32] INFO: Fitting label acetylation.\n",
      "[11-20-2017 07:13:32] INFO: Preparing data.\n",
      "[11-20-2017 07:13:39] INFO: Fitting classifier.\n",
      "[11-20-2017 07:13:42] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:13:42] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:13:42] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:13:42] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:13:43] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:13:43] INFO: Fitting label sumoylation.\n",
      "[11-20-2017 07:13:43] INFO: Preparing data.\n",
      "[11-20-2017 07:13:51] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:13:55] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:13:55] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:13:55] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:13:55] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:13:55] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:13:55] INFO: Fitting label glycosylation.\n",
      "[11-20-2017 07:13:55] INFO: Preparing data.\n",
      "[11-20-2017 07:14:03] INFO: Fitting classifier.\n",
      "[11-20-2017 07:14:07] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:14:07] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:14:07] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:14:07] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:14:07] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:14:07] INFO: Fitting label sulfation.\n",
      "[11-20-2017 07:14:07] INFO: Preparing data.\n",
      "[11-20-2017 07:14:15] INFO: Fitting classifier.\n",
      "[11-20-2017 07:14:18] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:14:18] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:14:18] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:14:18] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:14:18] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:14:18] INFO: Fitting label dissociation.\n",
      "[11-20-2017 07:14:18] INFO: Preparing data.\n",
      "[11-20-2017 07:14:27] INFO: Fitting classifier.\n",
      "[11-20-2017 07:14:33] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:14:33] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:14:33] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:14:33] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:14:33] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:14:33] INFO: Fitting label activation.\n",
      "[11-20-2017 07:14:33] INFO: Preparing data.\n",
      "[11-20-2017 07:14:42] INFO: Fitting classifier.\n",
      "[11-20-2017 07:14:55] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:14:55] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:14:55] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:14:55] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:14:56] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:14:56] INFO: Fitting label prenylation.\n",
      "[11-20-2017 07:14:56] INFO: Preparing data.\n",
      "[11-20-2017 07:15:04] INFO: Fitting classifier.\n",
      "[11-20-2017 07:15:07] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:15:07] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:15:07] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:15:07] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:15:07] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:15:07] INFO: Fitting label dephosphorylation.\n",
      "[11-20-2017 07:15:07] INFO: Preparing data.\n",
      "[11-20-2017 07:15:16] INFO: Fitting classifier.\n",
      "[11-20-2017 07:15:22] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:15:22] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:15:22] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:15:22] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:15:22] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:15:22] INFO: Fitting label myristoylation.\n",
      "[11-20-2017 07:15:22] INFO: Preparing data.\n",
      "[11-20-2017 07:15:30] INFO: Fitting classifier.\n",
      "[11-20-2017 07:15:32] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:15:32] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:15:32] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:15:32] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:15:32] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:15:32] INFO: Fitting label methylation.\n",
      "[11-20-2017 07:15:32] INFO: Preparing data.\n",
      "[11-20-2017 07:15:40] INFO: Fitting classifier.\n",
      "[11-20-2017 07:15:43] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:15:43] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:15:43] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:15:43] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:15:43] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:15:43] INFO: Fitting label inhibition.\n",
      "[11-20-2017 07:15:43] INFO: Preparing data.\n",
      "[11-20-2017 07:15:50] INFO: Fitting classifier.\n",
      "[11-20-2017 07:16:01] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:16:01] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:16:01] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:16:01] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:16:01] INFO: Computing top label features for fold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:16:01] INFO: Fitting label deacetylation.\n",
      "[11-20-2017 07:16:01] INFO: Preparing data.\n",
      "[11-20-2017 07:16:09] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:16:12] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:16:12] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:16:12] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:16:12] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:16:12] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:16:12] INFO: Fitting label ubiquitination.\n",
      "[11-20-2017 07:16:12] INFO: Preparing data.\n",
      "[11-20-2017 07:16:20] INFO: Fitting classifier.\n",
      "[11-20-2017 07:16:25] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:16:25] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:16:25] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:16:25] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:16:25] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:16:25] INFO: Fitting label state-change.\n",
      "[11-20-2017 07:16:25] INFO: Preparing data.\n",
      "[11-20-2017 07:16:33] INFO: Fitting classifier.\n",
      "[11-20-2017 07:16:38] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:16:38] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:16:38] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:16:38] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:16:38] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:16:38] INFO: Fitting label proteolytic-cleavage.\n",
      "[11-20-2017 07:16:38] INFO: Preparing data.\n",
      "[11-20-2017 07:16:46] INFO: Fitting classifier.\n",
      "[11-20-2017 07:16:52] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:16:52] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:16:52] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:16:52] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:16:52] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:16:52] INFO: Fitting label phosphorylation.\n",
      "[11-20-2017 07:16:52] INFO: Preparing data.\n",
      "[11-20-2017 07:17:00] INFO: Fitting classifier.\n",
      "[11-20-2017 07:17:16] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:17:16] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:17:16] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:17:16] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:17:16] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:17:16] INFO: Fitting label binding/association.\n",
      "[11-20-2017 07:17:16] INFO: Preparing data.\n",
      "[11-20-2017 07:17:25] INFO: Fitting classifier.\n",
      "[11-20-2017 07:17:35] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:17:35] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:17:35] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:17:35] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:17:35] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:17:35] INFO: Computing fold mult-label performance.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:17:41] INFO: Fitting fold iteration 2.\n",
      "[11-20-2017 07:17:41] INFO: Fitting label carboxylation.\n",
      "[11-20-2017 07:17:41] INFO: Preparing data.\n",
      "[11-20-2017 07:17:49] INFO: Fitting classifier.\n",
      "[11-20-2017 07:17:53] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:17:53] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:17:53] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:17:53] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:17:53] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:17:53] INFO: Fitting label acetylation.\n",
      "[11-20-2017 07:17:53] INFO: Preparing data.\n",
      "[11-20-2017 07:18:01] INFO: Fitting classifier.\n",
      "[11-20-2017 07:18:05] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:18:06] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:18:06] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:18:06] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:18:06] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:18:06] INFO: Fitting label sumoylation.\n",
      "[11-20-2017 07:18:06] INFO: Preparing data.\n",
      "[11-20-2017 07:18:13] INFO: Fitting classifier.\n",
      "[11-20-2017 07:18:17] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:18:17] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:18:17] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:18:17] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:18:17] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:18:17] INFO: Fitting label glycosylation.\n",
      "[11-20-2017 07:18:17] INFO: Preparing data.\n",
      "[11-20-2017 07:18:25] INFO: Fitting classifier.\n",
      "[11-20-2017 07:18:27] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:18:27] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:18:27] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:18:27] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:18:27] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:18:27] INFO: Fitting label sulfation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:18:27] INFO: Preparing data.\n",
      "[11-20-2017 07:18:34] INFO: Fitting classifier.\n",
      "[11-20-2017 07:18:37] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:18:37] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:18:37] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:18:37] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:18:37] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:18:37] INFO: Fitting label dissociation.\n",
      "[11-20-2017 07:18:37] INFO: Preparing data.\n",
      "[11-20-2017 07:18:44] INFO: Fitting classifier.\n",
      "[11-20-2017 07:18:49] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:18:49] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:18:49] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:18:49] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:18:49] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:18:49] INFO: Fitting label activation.\n",
      "[11-20-2017 07:18:49] INFO: Preparing data.\n",
      "[11-20-2017 07:18:56] INFO: Fitting classifier.\n",
      "[11-20-2017 07:19:11] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:19:11] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:19:11] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:19:11] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:19:11] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:19:11] INFO: Fitting label prenylation.\n",
      "[11-20-2017 07:19:11] INFO: Preparing data.\n",
      "[11-20-2017 07:19:18] INFO: Fitting classifier.\n",
      "[11-20-2017 07:19:22] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:19:22] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:19:22] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:19:22] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:19:22] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:19:22] INFO: Fitting label dephosphorylation.\n",
      "[11-20-2017 07:19:22] INFO: Preparing data.\n",
      "[11-20-2017 07:19:29] INFO: Fitting classifier.\n",
      "[11-20-2017 07:19:36] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:19:36] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:19:36] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:19:36] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:19:36] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:19:36] INFO: Fitting label myristoylation.\n",
      "[11-20-2017 07:19:36] INFO: Preparing data.\n",
      "[11-20-2017 07:19:45] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:19:48] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:19:48] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:19:48] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:19:48] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:19:48] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:19:48] INFO: Fitting label methylation.\n",
      "[11-20-2017 07:19:48] INFO: Preparing data.\n",
      "[11-20-2017 07:19:57] INFO: Fitting classifier.\n",
      "[11-20-2017 07:20:01] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:20:01] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:20:01] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:20:01] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:20:01] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:20:01] INFO: Fitting label inhibition.\n",
      "[11-20-2017 07:20:01] INFO: Preparing data.\n",
      "[11-20-2017 07:20:11] INFO: Fitting classifier.\n",
      "[11-20-2017 07:20:25] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:20:25] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:20:25] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:20:25] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:20:25] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:20:25] INFO: Fitting label deacetylation.\n",
      "[11-20-2017 07:20:25] INFO: Preparing data.\n",
      "[11-20-2017 07:20:35] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:20:38] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:20:38] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:20:38] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:20:38] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:20:38] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:20:38] INFO: Fitting label ubiquitination.\n",
      "[11-20-2017 07:20:38] INFO: Preparing data.\n",
      "[11-20-2017 07:20:47] INFO: Fitting classifier.\n",
      "[11-20-2017 07:20:53] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:20:53] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:20:53] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:20:53] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:20:53] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:20:53] INFO: Fitting label state-change.\n",
      "[11-20-2017 07:20:53] INFO: Preparing data.\n",
      "[11-20-2017 07:21:04] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:21:10] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:21:10] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:21:10] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:21:10] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:21:10] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:21:10] INFO: Fitting label proteolytic-cleavage.\n",
      "[11-20-2017 07:21:10] INFO: Preparing data.\n",
      "[11-20-2017 07:21:19] INFO: Fitting classifier.\n",
      "[11-20-2017 07:21:28] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:21:28] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:21:28] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:21:28] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:21:28] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:21:28] INFO: Fitting label phosphorylation.\n",
      "[11-20-2017 07:21:28] INFO: Preparing data.\n",
      "[11-20-2017 07:21:37] INFO: Fitting classifier.\n",
      "[11-20-2017 07:21:58] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:21:58] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:21:58] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:21:58] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:21:59] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:21:59] INFO: Fitting label binding/association.\n",
      "[11-20-2017 07:21:59] INFO: Preparing data.\n",
      "[11-20-2017 07:22:05] INFO: Fitting classifier.\n",
      "[11-20-2017 07:22:16] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:22:16] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:22:16] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:22:16] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:22:16] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:22:16] INFO: Computing fold mult-label performance.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:22:22] INFO: Fitting bootstrap iteration 2.\n",
      "[11-20-2017 07:22:25] INFO: Fitting fold iteration 1.\n",
      "[11-20-2017 07:22:25] INFO: Fitting label carboxylation.\n",
      "[11-20-2017 07:22:25] INFO: Preparing data.\n",
      "[11-20-2017 07:22:34] INFO: Fitting classifier.\n",
      "[11-20-2017 07:22:38] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:22:38] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:22:38] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:22:38] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:22:38] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:22:38] INFO: Fitting label acetylation.\n",
      "[11-20-2017 07:22:38] INFO: Preparing data.\n",
      "[11-20-2017 07:22:48] INFO: Fitting classifier.\n",
      "[11-20-2017 07:22:52] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:22:52] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:22:52] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:22:53] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:22:53] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:22:53] INFO: Fitting label sumoylation.\n",
      "[11-20-2017 07:22:53] INFO: Preparing data.\n",
      "[11-20-2017 07:23:01] INFO: Fitting classifier.\n",
      "[11-20-2017 07:23:07] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:23:07] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:23:07] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:23:07] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:23:07] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:23:07] INFO: Fitting label glycosylation.\n",
      "[11-20-2017 07:23:07] INFO: Preparing data.\n",
      "[11-20-2017 07:23:18] INFO: Fitting classifier.\n",
      "[11-20-2017 07:23:22] INFO: Making predictions on validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:23:22] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:23:22] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:23:22] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:23:22] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:23:22] INFO: Fitting label sulfation.\n",
      "[11-20-2017 07:23:22] INFO: Preparing data.\n",
      "[11-20-2017 07:23:33] INFO: Fitting classifier.\n",
      "[11-20-2017 07:23:37] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:23:37] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:23:37] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:23:37] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:23:37] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:23:37] INFO: Fitting label dissociation.\n",
      "[11-20-2017 07:23:37] INFO: Preparing data.\n",
      "[11-20-2017 07:23:47] INFO: Fitting classifier.\n",
      "[11-20-2017 07:23:55] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:23:55] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:23:55] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:23:55] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:23:55] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:23:55] INFO: Fitting label activation.\n",
      "[11-20-2017 07:23:55] INFO: Preparing data.\n",
      "[11-20-2017 07:24:05] INFO: Fitting classifier.\n",
      "[11-20-2017 07:24:22] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:24:22] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:24:22] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:24:22] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:24:22] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:24:22] INFO: Fitting label prenylation.\n",
      "[11-20-2017 07:24:22] INFO: Preparing data.\n",
      "[11-20-2017 07:24:30] INFO: Fitting classifier.\n",
      "[11-20-2017 07:24:34] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:24:34] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:24:34] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:24:34] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:24:34] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:24:34] INFO: Fitting label dephosphorylation.\n",
      "[11-20-2017 07:24:34] INFO: Preparing data.\n",
      "[11-20-2017 07:24:42] INFO: Fitting classifier.\n",
      "[11-20-2017 07:24:47] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:24:47] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:24:47] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:24:47] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:24:47] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:24:47] INFO: Fitting label myristoylation.\n",
      "[11-20-2017 07:24:47] INFO: Preparing data.\n",
      "[11-20-2017 07:24:56] INFO: Fitting classifier.\n",
      "[11-20-2017 07:24:59] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:24:59] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:24:59] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:24:59] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:24:59] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:24:59] INFO: Fitting label methylation.\n",
      "[11-20-2017 07:24:59] INFO: Preparing data.\n",
      "[11-20-2017 07:25:07] INFO: Fitting classifier.\n",
      "[11-20-2017 07:25:11] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:25:11] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:25:11] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:25:11] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:25:11] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:25:11] INFO: Fitting label inhibition.\n",
      "[11-20-2017 07:25:11] INFO: Preparing data.\n",
      "[11-20-2017 07:25:18] INFO: Fitting classifier.\n",
      "[11-20-2017 07:25:31] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:25:31] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:25:31] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:25:31] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:25:31] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:25:31] INFO: Fitting label deacetylation.\n",
      "[11-20-2017 07:25:31] INFO: Preparing data.\n",
      "[11-20-2017 07:25:39] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:25:42] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:25:42] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:25:42] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:25:42] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:25:42] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:25:42] INFO: Fitting label ubiquitination.\n",
      "[11-20-2017 07:25:42] INFO: Preparing data.\n",
      "[11-20-2017 07:25:53] INFO: Fitting classifier.\n",
      "[11-20-2017 07:25:58] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:25:58] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:25:58] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:25:58] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:25:58] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:25:58] INFO: Fitting label state-change.\n",
      "[11-20-2017 07:25:58] INFO: Preparing data.\n",
      "[11-20-2017 07:26:07] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:26:12] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:26:12] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:26:12] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:26:12] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:26:12] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:26:12] INFO: Fitting label proteolytic-cleavage.\n",
      "[11-20-2017 07:26:12] INFO: Preparing data.\n",
      "[11-20-2017 07:26:20] INFO: Fitting classifier.\n",
      "[11-20-2017 07:26:27] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:26:27] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:26:27] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:26:27] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:26:27] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:26:27] INFO: Fitting label phosphorylation.\n",
      "[11-20-2017 07:26:27] INFO: Preparing data.\n",
      "[11-20-2017 07:26:35] INFO: Fitting classifier.\n",
      "[11-20-2017 07:26:52] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:26:52] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:26:52] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:26:52] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:26:52] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:26:52] INFO: Fitting label binding/association.\n",
      "[11-20-2017 07:26:52] INFO: Preparing data.\n",
      "[11-20-2017 07:26:59] INFO: Fitting classifier.\n",
      "[11-20-2017 07:27:07] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:27:07] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:27:07] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:27:07] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:27:07] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:27:07] INFO: Computing fold mult-label performance.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:27:13] INFO: Fitting fold iteration 2.\n",
      "[11-20-2017 07:27:13] INFO: Fitting label carboxylation.\n",
      "[11-20-2017 07:27:14] INFO: Preparing data.\n",
      "[11-20-2017 07:27:22] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[11-20-2017 07:27:25] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:27:25] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:27:25] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:27:25] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:27:25] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:27:26] INFO: Fitting label acetylation.\n",
      "[11-20-2017 07:27:26] INFO: Preparing data.\n",
      "[11-20-2017 07:27:34] INFO: Fitting classifier.\n",
      "[11-20-2017 07:27:39] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:27:39] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:27:39] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:27:39] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:27:39] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:27:39] INFO: Fitting label sumoylation.\n",
      "[11-20-2017 07:27:39] INFO: Preparing data.\n",
      "[11-20-2017 07:27:48] INFO: Fitting classifier.\n",
      "[11-20-2017 07:27:52] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:27:52] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:27:53] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:27:53] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:27:53] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:27:53] INFO: Fitting label glycosylation.\n",
      "[11-20-2017 07:27:53] INFO: Preparing data.\n",
      "[11-20-2017 07:28:02] INFO: Fitting classifier.\n",
      "[11-20-2017 07:28:05] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:28:05] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:28:05] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:28:05] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:28:05] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:28:05] INFO: Fitting label sulfation.\n",
      "[11-20-2017 07:28:05] INFO: Preparing data.\n",
      "[11-20-2017 07:28:15] INFO: Fitting classifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:28:18] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:28:18] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:28:18] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:28:18] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:28:18] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:28:18] INFO: Fitting label dissociation.\n",
      "[11-20-2017 07:28:18] INFO: Preparing data.\n",
      "[11-20-2017 07:28:27] INFO: Fitting classifier.\n",
      "[11-20-2017 07:28:33] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:28:33] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:28:33] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:28:33] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:28:33] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:28:33] INFO: Fitting label activation.\n",
      "[11-20-2017 07:28:33] INFO: Preparing data.\n",
      "[11-20-2017 07:28:42] INFO: Fitting classifier.\n",
      "[11-20-2017 07:28:56] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:28:56] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:28:56] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:28:56] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:28:56] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:28:56] INFO: Fitting label prenylation.\n",
      "[11-20-2017 07:28:56] INFO: Preparing data.\n",
      "[11-20-2017 07:29:05] INFO: Fitting classifier.\n",
      "[11-20-2017 07:29:08] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:29:08] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:29:08] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:29:08] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:29:08] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:29:08] INFO: Fitting label dephosphorylation.\n",
      "[11-20-2017 07:29:08] INFO: Preparing data.\n",
      "[11-20-2017 07:29:17] INFO: Fitting classifier.\n",
      "[11-20-2017 07:29:23] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:29:23] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:29:23] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:29:23] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:29:23] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:29:23] INFO: Fitting label myristoylation.\n",
      "[11-20-2017 07:29:23] INFO: Preparing data.\n",
      "[11-20-2017 07:29:33] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:29:36] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:29:36] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:29:36] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:29:36] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:29:36] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:29:36] INFO: Fitting label methylation.\n",
      "[11-20-2017 07:29:36] INFO: Preparing data.\n",
      "[11-20-2017 07:29:46] INFO: Fitting classifier.\n",
      "[11-20-2017 07:29:50] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:29:50] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:29:50] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:29:50] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:29:50] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:29:50] INFO: Fitting label inhibition.\n",
      "[11-20-2017 07:29:50] INFO: Preparing data.\n",
      "[11-20-2017 07:30:00] INFO: Fitting classifier.\n",
      "[11-20-2017 07:30:14] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:30:14] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:30:14] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:30:14] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:30:14] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:30:14] INFO: Fitting label deacetylation.\n",
      "[11-20-2017 07:30:14] INFO: Preparing data.\n",
      "[11-20-2017 07:30:22] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:30:25] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:30:25] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:30:25] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:30:25] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:30:25] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:30:25] INFO: Fitting label ubiquitination.\n",
      "[11-20-2017 07:30:25] INFO: Preparing data.\n",
      "[11-20-2017 07:30:34] INFO: Fitting classifier.\n",
      "[11-20-2017 07:30:39] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:30:39] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:30:39] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:30:39] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:30:39] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:30:39] INFO: Fitting label state-change.\n",
      "[11-20-2017 07:30:39] INFO: Preparing data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:30:48] INFO: Fitting classifier.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[11-20-2017 07:30:53] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:30:53] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:30:53] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:30:53] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:30:53] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:30:53] INFO: Fitting label proteolytic-cleavage.\n",
      "[11-20-2017 07:30:53] INFO: Preparing data.\n",
      "[11-20-2017 07:31:01] INFO: Fitting classifier.\n",
      "[11-20-2017 07:31:07] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:31:07] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:31:07] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:31:07] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:31:07] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:31:07] INFO: Fitting label phosphorylation.\n",
      "[11-20-2017 07:31:07] INFO: Preparing data.\n",
      "[11-20-2017 07:31:16] INFO: Fitting classifier.\n",
      "[11-20-2017 07:31:30] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:31:30] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:31:30] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:31:30] INFO: Storing testing predictions.\n",
      "[11-20-2017 07:31:30] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:31:30] INFO: Fitting label binding/association.\n",
      "[11-20-2017 07:31:30] INFO: Preparing data.\n",
      "[11-20-2017 07:31:39] INFO: Fitting classifier.\n",
      "[11-20-2017 07:31:49] INFO: Making predictions on validation data.\n",
      "[11-20-2017 07:31:49] INFO: Making predictions on testing data.\n",
      "[11-20-2017 07:31:49] INFO: Storing validation predictions.\n",
      "[11-20-2017 07:31:49] INFO: Storing testing predictions.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[11-20-2017 07:31:49] INFO: Computing top label features for fold.\n",
      "[11-20-2017 07:31:49] INFO: Computing fold mult-label performance.\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/envs/pyppi/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Begin the main show!\n",
    "# ------------------------------------------------------------------- #\n",
    "for bs_iter in range(n_iter):\n",
    "    logging.info(\"Fitting bootstrap iteration {}.\".format(bs_iter + 1))\n",
    "    cv = IterativeStratifiedKFold(n_splits=n_splits, random_state=seeds[bs_iter])\n",
    "    \n",
    "    for fold_iter, (train_idx, validation_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        logging.info(\"Fitting fold iteration {}.\".format(fold_iter + 1))\n",
    "        y_valid_f_pred = []\n",
    "        y_test_f_pred = []\n",
    "        y_valid_f_proba = []\n",
    "        y_test_f_proba = []\n",
    "        \n",
    "        for label_idx, label in enumerate(mlb.classes):\n",
    "            logging.info(\"Fitting label {}.\".format(label))\n",
    "            \n",
    "            # Prepare all training and testing data\n",
    "            logging.info(\"Preparing data.\")\n",
    "            vectorizer = CountVectorizer(binary=True if use_binary else False)\n",
    "            vectorizer.fit(X_train[train_idx])\n",
    "\n",
    "            X_train_l = vectorizer.transform(X_train[train_idx])\n",
    "            y_train_l = y_train[train_idx, label_idx]\n",
    "\n",
    "            X_valid_l = vectorizer.transform(X_train[validation_idx])\n",
    "            y_valid_l = y_train[validation_idx, label_idx]\n",
    "\n",
    "            X_test_l = vectorizer.transform(X_test)\n",
    "            y_test_l = y_test[:, label_idx]\n",
    "            \n",
    "            # Build and fit classifier\n",
    "            logging.info(\"Fitting classifier.\")\n",
    "            base_est = make_classifier(\n",
    "                algorithm=model, \n",
    "                random_state=0\n",
    "            )\n",
    "            clf = RandomizedSearchCV(\n",
    "                estimator=base_est,\n",
    "                scoring='f1', \n",
    "                error_score=0,\n",
    "                cv=3,\n",
    "                n_iter=hyperparam_iter, \n",
    "                n_jobs=n_jobs, \n",
    "                refit=True, \n",
    "                random_state=0, \n",
    "                param_distributions=params,\n",
    "            )\n",
    "            try:\n",
    "                clf.fit(X_train_l, y_train_l)\n",
    "            except TypeError:\n",
    "                logger.info(\"Error fitting sparse input. Converting to dense input.\")\n",
    "                X_train_l = X_train_l.todense()\n",
    "                X_valid_l = X_valid_l.todense()\n",
    "                X_test_l = X_test_l.todense()\n",
    "                clf.fit(X_train_l, y_train_l)\n",
    "            \n",
    "            # Validation scores in binary and probability format\n",
    "            logging.info(\"Making predictions on validation data.\")\n",
    "            y_valid_l_pred = clf.predict(X_valid_l)\n",
    "            y_valid_l_proba = clf.predict_proba(X_valid_l)\n",
    "\n",
    "            # Held-out testing scores in binary and probability format\n",
    "            logging.info(\"Making predictions on testing data.\")\n",
    "            y_test_l_pred = clf.predict(X_test_l)\n",
    "            y_test_l_proba = clf.predict_proba(X_test_l)\n",
    "\n",
    "            # Store these per label results in a list which we will\n",
    "            # later use to stack into a multi-label array.\n",
    "            logging.info(\"Storing validation predictions.\")\n",
    "            y_valid_f_pred.append([[x] for x in y_valid_l_pred])\n",
    "            y_valid_f_proba.append([[x[1]] for x in y_valid_l_proba])\n",
    "\n",
    "            logging.info(\"Storing testing predictions.\")\n",
    "            y_test_f_pred.append([[x] for x in y_test_l_pred])\n",
    "            y_test_f_proba.append([[x[1]] for x in y_test_l_proba])\n",
    "            \n",
    "            # Perform scoring on the validation set and the external testing set.\n",
    "             \n",
    "            for func_idx, (func_name, func) in enumerate(binary_scoring_funcs):\n",
    "                if func_name in ['Specificity', 'FDR']:\n",
    "                    scores_v = func(y_valid_l, y_valid_l_pred)\n",
    "                    scores_t = func(y_test_l, y_test_l_pred)\n",
    "                else:\n",
    "                    scores_v = func(y_valid_l, y_valid_l_pred, average='binary')\n",
    "                    scores_t = func(y_test_l, y_test_l_pred, average='binary')\n",
    "                binary_statistics[label_idx, 0, func_idx, bs_iter, fold_iter] = scores_v\n",
    "                binary_statistics[label_idx, 1, func_idx, bs_iter, fold_iter] = scores_t\n",
    "                \n",
    "            logging.info(\"Computing top label features for fold.\")\n",
    "            # Get the top 20 features for this labels's run.\n",
    "            top_n = top_n_features(\n",
    "                clf=clf,\n",
    "                go_dag=go_dag,\n",
    "                ipr_map=ipr_map,\n",
    "                pfam_map=pfam_map,\n",
    "                n=get_top_n,\n",
    "                absolute=abs_weights,\n",
    "                vectorizer=vectorizer\n",
    "            )\n",
    "            top_features[label][bs_iter][fold_iter].extend(top_n)\n",
    "        \n",
    "        logging.info(\"Computing fold mult-label performance.\")\n",
    "        # True scores in multi-label indicator format\n",
    "        y_valid_f = y_train[validation_idx]\n",
    "        y_test_f = y_test\n",
    "\n",
    "        # Validation scores in multi-label indicator format\n",
    "        y_valid_f_pred = np.hstack(y_valid_f_pred)\n",
    "        y_valid_f_proba = np.hstack(y_valid_f_proba)\n",
    "\n",
    "        # Testing scores in multi-label probability format\n",
    "        y_test_f_pred = np.hstack(y_test_f_pred)\n",
    "        y_test_f_proba = np.hstack(y_test_f_proba)\n",
    "           \n",
    "        for func_idx, (func_name, func) in enumerate(multilabel_scoring_funcs):\n",
    "            if func_name == 'Macro (weighted) F1':\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred, average='weighted')\n",
    "                scores_t = func(y_test_f, y_test_f_pred, average='weighted')\n",
    "            elif func_name == 'Macro (un-weighted) F1':\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred, average='macro')\n",
    "                scores_t = func(y_test_f, y_test_f_pred, average='macro')\n",
    "            elif func_name == 'Label Ranking Average Precision':\n",
    "                scores_v = func(y_valid_f, y_valid_f_proba)\n",
    "                scores_t = func(y_test_f, y_test_f_proba)\n",
    "            else:\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred)\n",
    "                scores_t = func(y_test_f, y_test_f_pred)\n",
    "                \n",
    "            multilabel_statistics[0, func_idx, bs_iter, fold_iter] = scores_v\n",
    "            multilabel_statistics[1, func_idx, bs_iter, fold_iter] = scores_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11-20-2017 07:31:56] INFO: Writing statistics to file.\n",
      "[11-20-2017 07:31:56] INFO: Writing label training order.\n",
      "[11-20-2017 07:31:56] INFO: Writing top features to file.\n"
     ]
    }
   ],
   "source": [
    "# Write out all the statistics to a multi-indexed dataframe\n",
    "# -------------------------------------------------------------------- #\n",
    "logging.info(\"Writing statistics to file.\")\n",
    "\n",
    "# Binary Statistics\n",
    "# -------------------------------------------------------------------- #\n",
    "dim_a_size = len(mlb.classes) * 2 * len(binary_scoring_funcs)\n",
    "dim_b_size = n_iter * n_splits\n",
    "\n",
    "func_names = [n for n, _ in binary_scoring_funcs]\n",
    "iterables = [mlb.classes, [\"validation\", \"holdout\"], func_names]\n",
    "names = ['Labels', 'Condition', 'Metric']\n",
    "tuples = list(product(*iterables))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=names)\n",
    "\n",
    "names = ['Bootstrap Iteration', 'Fold Iteration']\n",
    "arrays = [\n",
    "    ['B{}'.format(i+1) for i in range(n_iter)],\n",
    "    ['F{}'.format(i+1) for i in range(n_splits)]\n",
    "]\n",
    "tuples = list(product(*arrays))\n",
    "columns = pd.MultiIndex.from_tuples(tuples, names=names)\n",
    "\n",
    "binary_df = pd.DataFrame(\n",
    "    binary_statistics.reshape((dim_a_size, dim_b_size)),\n",
    "    index=index, columns=columns\n",
    ").sort_index()\n",
    "binary_df.to_csv('{}/{}'.format(direc, 'binary_stats.csv'), sep=',')\n",
    "\n",
    "# Multi-label Statistics\n",
    "# -------------------------------------------------------------------- #\n",
    "dim_a_size = 2 * len(multilabel_scoring_funcs)\n",
    "dim_b_size = n_iter * n_splits\n",
    "\n",
    "func_names = [n for n, _ in multilabel_scoring_funcs]\n",
    "iterables = [[\"validation\", \"holdout\"], func_names]\n",
    "names = ['Condition', 'Metric']\n",
    "tuples = list(product(*iterables))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=names)\n",
    "\n",
    "names = ['Bootstrap Iteration', 'Fold Iteration']\n",
    "arrays = [\n",
    "    ['B{}'.format(i+1) for i in range(n_iter)],\n",
    "    ['F{}'.format(i+1) for i in range(n_splits)]\n",
    "]\n",
    "tuples = list(product(*arrays))\n",
    "columns = pd.MultiIndex.from_tuples(tuples, names=names)\n",
    "\n",
    "multilabel_df = pd.DataFrame(\n",
    "    multilabel_statistics.reshape((dim_a_size, dim_b_size)),\n",
    "    index=index, columns=columns\n",
    ").sort_index()\n",
    "multilabel_df.to_csv(\n",
    "    '{}/{}'.format(direc, 'multilabel_stats.csv'), sep=','\n",
    ")\n",
    "\n",
    "# Top N Features, train/y-array index order\n",
    "# -------------------------------------------------------------------- #\n",
    "logging.info(\"Writing label training order.\")\n",
    "with open(\"{}/{}\".format(direc, \"label_order.csv\"), 'wt') as fp:\n",
    "    fp.write(\",\".join(mlb.classes))\n",
    "\n",
    "logging.info(\"Writing top features to file.\")\n",
    "with open('{}/{}'.format(direc, 'top_features.json'), 'wt') as fp:\n",
    "    json.dump(top_features, fp, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute label similarity heatmaps and label correlation heatmap\n",
    "# -------------------------------------------------------------------- #\n",
    "label_features = {l: set() for l in mlb.classes}\n",
    "for idx, label in enumerate(mlb.classes):\n",
    "    selector = y_train[:, idx] == 1\n",
    "    positive_cases = X_train[selector]\n",
    "    for feature_string in positive_cases:\n",
    "        unique = set(feature_string.split(','))\n",
    "        label_features[label] |= unique\n",
    "        \n",
    "j_v_similarity_matrix = np.zeros((len(mlb.classes), len(mlb.classes)))\n",
    "d_v_similarity_matrix = np.zeros((len(mlb.classes), len(mlb.classes)))\n",
    "for i, class_1 in enumerate(sorted(mlb.classes)):\n",
    "    for j, class_2 in enumerate(sorted(mlb.classes)):\n",
    "        set_1 = label_features[class_1]\n",
    "        set_2 = label_features[class_2]\n",
    "        jaccard = len(set_1 & set_2) / len(set_1 | set_2)\n",
    "        dice = 2 * len(set_1 & set_2) / (len(set_1) + len(set_2))\n",
    "        j_v_similarity_matrix[i, j] = jaccard\n",
    "        d_v_similarity_matrix[i, j] = dice\n",
    "        \n",
    "\n",
    "# Create label correlation matrix and then create a new one\n",
    "# Where the columns and rows are in alphabetical order.\n",
    "label_correlation, _ = sp.stats.spearmanr(y_train)\n",
    "s_label_correlation = np.zeros_like(label_correlation)\n",
    "for i, class_1 in enumerate(sorted(mlb.classes)):\n",
    "    for j, class_2 in enumerate(sorted(mlb.classes)):\n",
    "        index_1 = mlb.classes.index(class_1)\n",
    "        index_2 = mlb.classes.index(class_2)\n",
    "        s_label_correlation[i, j] = label_correlation[index_1, index_2]\n",
    "\n",
    "\n",
    "header = \"Columns: {}\\nRows: {}\".format(\n",
    "    ','.join(sorted(mlb.classes)), ','.join(sorted(mlb.classes))\n",
    ")\n",
    "np.savetxt(\n",
    "    X=j_v_similarity_matrix,\n",
    "    fname='{}/{}'.format(direc, 'j_v_similarity_matrix.csv'),\n",
    "    header=header, delimiter=','\n",
    ")\n",
    "np.savetxt(\n",
    "    X=d_v_similarity_matrix,\n",
    "    fname='{}/{}'.format(direc, 'd_v_similarity_matrix.csv'),\n",
    "    header=header, delimiter=','\n",
    ")\n",
    "np.savetxt(\n",
    "    X=s_label_correlation, fname='{}/{}'.format(direc, 'label_spearmanr.csv'),\n",
    "    header=header, delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dephosphorylation acetylation 0.14422288992078666\n",
      "dephosphorylation activation 0.18240910014218972\n",
      "dephosphorylation binding/association 0.22319705211440605\n",
      "dephosphorylation carboxylation 0.01785123966942149\n",
      "dephosphorylation deacetylation 0.07436460621273926\n",
      "dephosphorylation dephosphorylation 0.3471575966012543\n",
      "dephosphorylation dissociation 0.23177392543338873\n",
      "dephosphorylation glycosylation 0.1863555818074424\n",
      "dephosphorylation inhibition 0.2335575485799701\n",
      "dephosphorylation methylation 0.12930788949017374\n",
      "dephosphorylation myristoylation 0.11840796019900497\n",
      "dephosphorylation phosphorylation 0.2721546961325967\n",
      "dephosphorylation prenylation 0.0901301174230403\n",
      "dephosphorylation proteolytic-cleavage 0.26478790547482756\n",
      "dephosphorylation state-change 0.12416979497545481\n",
      "dephosphorylation sulfation 0.03739837398373984\n",
      "dephosphorylation sumoylation 0.15611233480176212\n",
      "dephosphorylation ubiquitination 0.29368372521899494\n",
      "phosphorylation acetylation 0.10865648999715559\n",
      "phosphorylation activation 0.4871932332618537\n",
      "phosphorylation binding/association 0.4930381509328878\n",
      "phosphorylation carboxylation 0.008673274876096072\n",
      "phosphorylation deacetylation 0.040266539742979536\n",
      "phosphorylation dephosphorylation 0.29959625619379704\n",
      "phosphorylation dissociation 0.18419333768778576\n",
      "phosphorylation glycosylation 0.0922449753507774\n",
      "phosphorylation inhibition 0.49300648882480175\n",
      "phosphorylation methylation 0.07882607468723545\n",
      "phosphorylation myristoylation 0.039273769708552314\n",
      "phosphorylation phosphorylation 0.5290664951354829\n",
      "phosphorylation prenylation 0.03824981017463933\n",
      "phosphorylation proteolytic-cleavage 0.3324241672865526\n",
      "phosphorylation state-change 0.0764072534945221\n",
      "phosphorylation sulfation 0.02100439182738209\n",
      "phosphorylation sumoylation 0.10145882352941177\n",
      "phosphorylation ubiquitination 0.20851377499308946\n"
     ]
    }
   ],
   "source": [
    "# Compute label similarity heatmaps for the holdout set\n",
    "# -------------------------------------------------------------------- #\n",
    "holdout_labels = ('dephosphorylation', 'phosphorylation')\n",
    "holdout_label_features = {l: set() for l in holdout_labels}\n",
    "for idx, label in enumerate(mlb.classes):\n",
    "    if label in holdout_labels:\n",
    "        selector = y_test[:, idx] == 1\n",
    "        positive_cases = X_test[selector]\n",
    "        for feature_string in positive_cases:\n",
    "            unique = set(feature_string.split(','))\n",
    "            holdout_label_features[label] |= unique\n",
    "        \n",
    "j_t_similarity_matrix = np.zeros((2, len(mlb.classes)))\n",
    "d_t_similarity_matrix = np.zeros((2, len(mlb.classes)))\n",
    "for i, class_1 in enumerate(sorted(holdout_labels)):\n",
    "    for j, class_2 in enumerate(sorted(mlb.classes)):\n",
    "        set_1 = holdout_label_features[class_1]\n",
    "        set_2 = label_features[class_2]\n",
    "        jaccard = len(set_1 & set_2) / len(set_1 | set_2)\n",
    "        dice = 2 * len(set_1 & set_2) / (len(set_1) + len(set_2))\n",
    "        j_t_similarity_matrix[i, j] = jaccard\n",
    "        d_t_similarity_matrix[i, j] = dice\n",
    "        \n",
    "header = \"Columns: {}\\nRows: {}\".format(\n",
    "    ','.join(sorted(mlb.classes)), ','.join(sorted(holdout_labels))\n",
    ")\n",
    "np.savetxt(\n",
    "    X=j_t_similarity_matrix, \n",
    "    fname='{}/{}'.format(direc, 'j_t_similarity_matrix.csv'), \n",
    "    header=header, delimiter=','\n",
    ")\n",
    "np.savetxt(\n",
    "    X=d_t_similarity_matrix, \n",
    "    fname='{}/{}'.format(direc, 'd_t_similarity_matrix.csv'), \n",
    "    header=header, delimiter=','\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyppi]",
   "language": "python",
   "name": "conda-env-pyppi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
