{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "\"\"\"\n",
    "This script runs the bootstrap kfold validation experiments as used in\n",
    "the publication.\n",
    "\n",
    "Usage:\n",
    "  validation.py [--interpro] [--pfam] [--mf] [--cc] [--bp]\n",
    "             [--use_cache] [--induce] [--verbose]\n",
    "             [--model=M] [--n_jobs=J] [--n_splits=S] [--n_iterations=I]\n",
    "             [--directory=DIR]\n",
    "  validation.py -h | --help\n",
    "\n",
    "Options:\n",
    "  -h --help     Show this screen.\n",
    "  --interpro    Use interpro domains in features.\n",
    "  --pfam        Use Pfam domains in features.\n",
    "  --mf          Use Molecular Function Gene Ontology in features.\n",
    "  --cc          Use Cellular Compartment Gene Ontology in features.\n",
    "  --bp          Use Biological Process Gene Ontology in features.\n",
    "  --induce      Use ULCA inducer over Gene Ontology.\n",
    "  --verbose     Print intermediate output for debugging.\n",
    "  --use_cache   Use cached features if available.\n",
    "  --model=M         A binary classifier from Scikit-Learn implementing fit,\n",
    "                    predict and predict_proba [default: LogisticRegression]\n",
    "  --n_jobs=J        Number of processes to run in parallel [default: 1]\n",
    "  --n_splits=S      Number of cross-validation splits [default: 5]\n",
    "  --n_iterations=I  Number of bootstrap iterations [default: 5]\n",
    "  --directory=DIR   Output directory [default: ./results/]\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from pyppi.base import parse_args, su_make_dir\n",
    "from pyppi.data import load_network_from_path, load_ptm_labels\n",
    "from pyppi.data import testing_network_path, training_network_path\n",
    "\n",
    "from pyppi.models.binary_relevance import BinaryRelevance\n",
    "from pyppi.models import make_classifier\n",
    "from pyppi.model_selection.scoring import MultilabelScorer, Statistics\n",
    "from pyppi.model_selection.experiment import KFoldExperiment, Bootstrap\n",
    "from pyppi.model_selection.sampling import IterativeStratifiedKFold\n",
    "\n",
    "from pyppi.data_mining.features import AnnotationExtractor\n",
    "from pyppi.data_mining.uniprot import UniProt, get_active_instance\n",
    "from pyppi.data_mining.tools import xy_from_interaction_frame\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.metrics import (\n",
    "    recall_score, make_scorer, label_ranking_average_precision_score)\n",
    "\n",
    "args = {\n",
    "    'n_jobs': 1,\n",
    "    'n_splits': 5,\n",
    "    'n_iterations': 5,\n",
    "    'induce': True,\n",
    "    'verbose': True,\n",
    "    'selection': [\n",
    "        UniProt.data_types().GO_MF.value,\n",
    "        UniProt.data_types().GO_BP.value,\n",
    "        UniProt.data_types().GO_CC.value,\n",
    "        UniProt.data_types().INTERPRO.value,\n",
    "        UniProt.data_types().PFAM.value\n",
    "    ],\n",
    "    'model': 'LogisticRegression',\n",
    "    'use_cache': True,\n",
    "    'direc': './results/'\n",
    "}\n",
    "n_jobs = args['n_jobs']\n",
    "n_splits = args['n_splits']\n",
    "n_iter = args['n_iterations']\n",
    "induce = args['induce']\n",
    "verbose = args['verbose']\n",
    "selection = args['selection']\n",
    "model = args['model']\n",
    "use_feature_cache = args['use_cache']\n",
    "direc = args['directory']\n",
    "backend = 'multiprocessing'\n",
    "\n",
    "# Set up the folder for each experiment run named after the current time\n",
    "folder = datetime.now().strftime(\"val_%y-%m-%d_%H-%M\")\n",
    "direc = \"{}/{}/\".format(direc, folder)\n",
    "su_make_dir(direc)\n",
    "json.dump(\n",
    "    args, fp=open(\"{}/settings.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "uniprot = get_active_instance(\n",
    "    verbose=verbose,\n",
    "    sprot_cache=None,\n",
    "    trembl_cache=None\n",
    ")\n",
    "data_types = UniProt.data_types()\n",
    "labels = load_ptm_labels()\n",
    "annotation_ex = AnnotationExtractor(\n",
    "    induce=induce,\n",
    "    selection=selection,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    "    cache=use_feature_cache,\n",
    "    backend='threading'\n",
    ")\n",
    "training = load_network_from_path(training_network_path)\n",
    "testing = load_network_from_path(testing_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the features into X, and multilabel y indicator format\n",
    "print(\"Preparing training and testing data...\")\n",
    "mlb = MultiLabelBinarizer(classes=labels)\n",
    "X_train_ppis, y_train = xy_from_interaction_frame(training)\n",
    "X_test_ppis, y_test = xy_from_interaction_frame(testing)\n",
    "mlb.fit(y_train)\n",
    "\n",
    "X_train = annotation_ex.transform(X_train_ppis)\n",
    "X_test = annotation_ex.transform(X_test_ppis)\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the estimators and BR classifier\n",
    "print(\"Making classifier...\")\n",
    "param_distribution = {\n",
    "    'C': np.arange(0.01, 20.01, step=0.01),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "def make_rcv():\n",
    "    random_cv = RandomizedSearchCV(\n",
    "        cv=3,\n",
    "        n_jobs=1,\n",
    "        n_iter=60,\n",
    "        param_distributions=param_distribution,\n",
    "        estimator=make_classifier(model),\n",
    "        scoring=make_scorer(f1_score, greater_is_better=True)\n",
    "    )\n",
    "    return random_cv\n",
    "\n",
    "estimators = [\n",
    "    Pipeline(\n",
    "        [('vectorizer', CountVectorizer(binary=False)),\n",
    "         ('clf', make_rcv())]\n",
    "    )\n",
    "    for l in labels\n",
    "]\n",
    "clf = BinaryRelevance(estimators, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the bootstrap and KFoldExperiments\n",
    "print(\"Setting up experiments...\")\n",
    "cv = IterativeStratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "kf = KFoldExperiment(\n",
    "    estimator=clf, cv=cv, n_jobs=n_jobs,\n",
    "    verbose=verbose, backend=backend\n",
    ")\n",
    "bootstrap = Bootstrap(\n",
    "    kfold_experiemnt=kf, n_iter=n_iter, n_jobs=1,\n",
    "    verbose=verbose, backend=backend\n",
    ")\n",
    "\n",
    "# Fit the data\n",
    "print(\"Fitting training data...\")\n",
    "bootstrap.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the scoring functions\n",
    "print(\"Evaluating performance...\")\n",
    "f1_scorer = MultilabelScorer(f1_score)\n",
    "recall_scorer = MultilabelScorer(recall_score)\n",
    "precision_scorer = MultilabelScorer(precision_score)\n",
    "score_funcs = [recall_scorer, precision_scorer, f1_scorer]\n",
    "thresholds = [0.5, 0.5, 0.5]\n",
    "\n",
    "# Evaluate performance\n",
    "validation_data = bootstrap.validation_scores(\n",
    "    X_train, y_train, score_funcs, thresholds, True, False\n",
    ")\n",
    "testing_data = bootstrap.held_out_scores(\n",
    "    X_test, y_test, score_funcs, thresholds, True, False\n",
    ")\n",
    "\n",
    "# Put everything into a dataframe\n",
    "print(\"Saving statistics dataframes...\")\n",
    "validation_stats = Statistics.statistics_from_data(\n",
    "    data=validation_data,\n",
    "    statistics_names=['Recall', 'Precision', 'F1'],\n",
    "    classes=mlb.classes_,\n",
    "    return_df=True\n",
    ")\n",
    "# Put everything into a dataframe\n",
    "testing_stats = Statistics.statistics_from_data(\n",
    "    data=testing_data,\n",
    "    statistics_names=['Recall', 'Precision', 'F1'],\n",
    "    classes=mlb.classes_,\n",
    "    return_df=True\n",
    ")\n",
    "validation_stats.to_csv(\n",
    "    '{}/validation_stats.csv'.format(direc), sep='\\t', index=False\n",
    ")\n",
    "testing_stats.to_csv(\n",
    "    '{}/testing_stats.csv'.format(direc), sep='\\t', index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Writing top features...\")\n",
    "with open('{}/{}'.format(folder, 'top_features'), 'wt') as fp:\n",
    "    classes = mlb.classes\n",
    "    top_features = clf.top_n_features(20, absolute=True)\n",
    "    for label, (fs, ws) in zip(classes, top_features):\n",
    "        fp.write(\"{}\\n\".format(label))\n",
    "        for line in ['\\t'.join(tup) for tup in zip(fs, ws)]:\n",
    "            fp.write(\"{}\\n\".format(line))\n",
    "        fp.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyppi]",
   "language": "python",
   "name": "conda-env-pyppi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
