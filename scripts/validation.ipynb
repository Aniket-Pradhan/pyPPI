{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results//val_17-08-26_17-49/ already exists...\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"\n",
    "This script runs the bootstrap kfold validation experiments as used in\n",
    "the publication. Change `args` to suit your needs.\n",
    "\n",
    "Usage:\n",
    "  validation.py [--interpro] [--pfam] [--mf] [--cc] [--bp]\n",
    "             [--use_cache] [--induce] [--verbose] [--abs] [--top=T]\n",
    "             [--model=M] [--n_jobs=J] [--n_splits=S] [--n_iterations=I]\n",
    "             [--h_iterations=H] [--directory=DIR]\n",
    "  validation.py -h | --help\n",
    "\n",
    "Options:\n",
    "  -h --help     Show this screen.\n",
    "  --interpro    Use interpro domains in features.\n",
    "  --pfam        Use Pfam domains in features.\n",
    "  --mf          Use Molecular Function Gene Ontology in features.\n",
    "  --cc          Use Cellular Compartment Gene Ontology in features.\n",
    "  --bp          Use Biological Process Gene Ontology in features.\n",
    "  --induce      Use ULCA inducer over Gene Ontology.\n",
    "  --verbose     Print intermediate output for debugging.\n",
    "  --use_cache   Use cached features if available.\n",
    "  --abs         Take the absolute value of feature weights when computing top features.\n",
    "  --top=T       Top T features for each label to log [default: 25]\n",
    "  --model=M         A binary classifier from Scikit-Learn implementing fit,\n",
    "                    predict and predict_proba [default: LogisticRegression]\n",
    "  --n_jobs=J        Number of processes to run in parallel [default: 1]\n",
    "  --n_splits=S      Number of cross-validation splits [default: 5]\n",
    "  --h_iterations=H  Number of hyperparameter tuning iterations per fold [default: 60]\n",
    "  --n_iterations=I  Number of bootstrap iterations [default: 5]\n",
    "  --directory=DIR   Output directory [default: ./results/]\n",
    "  \n",
    "  jupyter nbconvert --to=html --ExecutePreprocessor.enabled=True notebook.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "from pyppi.base import parse_args, su_make_dir\n",
    "from pyppi.data import load_network_from_path, load_ptm_labels\n",
    "from pyppi.data import testing_network_path, training_network_path\n",
    "from pyppi.data import get_term_description, ipr_name_map, pfam_name_map\n",
    "\n",
    "\n",
    "from pyppi.models.binary_relevance import get_coefs, top_n_features\n",
    "from pyppi.models import make_classifier, get_parameter_distribution_form_model\n",
    "from pyppi.models import supported_estimators\n",
    "from pyppi.model_selection.scoring import fdr_score, specificity\n",
    "from pyppi.model_selection.sampling import IterativeStratifiedKFold\n",
    "\n",
    "from pyppi.data_mining.features import AnnotationExtractor\n",
    "from pyppi.data_mining.uniprot import UniProt, get_active_instance\n",
    "from pyppi.data_mining.tools import xy_from_interaction_frame\n",
    "from pyppi.data_mining.ontology import get_active_instance as load_godag\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import (\n",
    "    recall_score, make_scorer, \n",
    "    label_ranking_average_precision_score,\n",
    "    label_ranking_loss,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "logging.captureWarnings(False)\n",
    "logging.basicConfig(\n",
    "    format='[%(asctime)s] %(levelname)s: %(message)s', \n",
    "    datefmt='%m-%d-%Y %I:%M:%S',\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "args = {\n",
    "    'n_jobs': 3,\n",
    "    'n_splits': 2,\n",
    "    'n_iterations': 1,\n",
    "    'h_iterations': 3,\n",
    "    'induce': True,\n",
    "    'verbose': True,\n",
    "    'abs': True,\n",
    "    'top': 25,\n",
    "    'selection': [\n",
    "        UniProt.data_types().GO_MF.value,\n",
    "        UniProt.data_types().GO_BP.value,\n",
    "        UniProt.data_types().GO_CC.value,\n",
    "        UniProt.data_types().INTERPRO.value,\n",
    "        UniProt.data_types().PFAM.value\n",
    "    ],\n",
    "    'model': 'LogisticRegression',\n",
    "    'use_cache': True,\n",
    "    'directory': './results/'\n",
    "}\n",
    "n_jobs = args['n_jobs']\n",
    "n_splits = args['n_splits']\n",
    "n_iter = args['n_iterations']\n",
    "induce = args['induce']\n",
    "verbose = args['verbose']\n",
    "selection = args['selection']\n",
    "model = args['model']\n",
    "use_feature_cache = args['use_cache']\n",
    "direc = args['directory']\n",
    "hyperparam_iter = args['h_iterations']\n",
    "get_top_n = args['top']\n",
    "abs_weights = args['abs']\n",
    "\n",
    "# Set up the folder for each experiment run named after the current time\n",
    "folder = datetime.now().strftime(\"val_%y-%m-%d_%H-%M\")\n",
    "direc = \"{}/{}/\".format(direc, folder)\n",
    "su_make_dir(direc)\n",
    "json.dump(\n",
    "    args, fp=open(\"{}/settings.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:49:48] INFO: Loading training and testing data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time loading on UniProt instance. Make take a few moments\n",
      "Warning: Loading dat files, may take a few minutes.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Loading training and testing data.\")\n",
    "ipr_map = ipr_name_map(short_names=False)\n",
    "pfam_map = pfam_name_map()\n",
    "go_dag = load_godag()\n",
    "uniprot = get_active_instance(\n",
    "    verbose=verbose,\n",
    "    sprot_cache=None,\n",
    "    trembl_cache=None\n",
    ")\n",
    "data_types = UniProt.data_types()\n",
    "labels = load_ptm_labels()\n",
    "annotation_ex = AnnotationExtractor(\n",
    "    induce=induce,\n",
    "    selection=selection,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=verbose,\n",
    "    cache=use_feature_cache,\n",
    "    backend='multiprocessing'\n",
    ")\n",
    "training = load_network_from_path(training_network_path)\n",
    "testing = load_network_from_path(testing_network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:50:28] INFO: Preparing training and testing data.\n",
      "[08-26-2017 05:50:28] INFO: Computing class distributions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n",
      "Finding new PPIs...\n",
      "Stringing selected features for each PPI...\n"
     ]
    }
   ],
   "source": [
    "# Get the features into X, and multilabel y indicator format\n",
    "logging.info(\"Preparing training and testing data.\")\n",
    "mlb = MultiLabelBinarizer(classes=labels, sparse_output=False)\n",
    "X_train_ppis, y_train = xy_from_interaction_frame(training)\n",
    "X_test_ppis, y_test = xy_from_interaction_frame(testing)\n",
    "mlb.fit(y_train)\n",
    "\n",
    "logging.info(\"Computing class distributions.\")\n",
    "json.dump(\n",
    "    Counter([l for ls in y_train for l in ls]), \n",
    "    fp=open(\"{}/training_distribution.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True\n",
    ")\n",
    "json.dump(\n",
    "    Counter([l for ls in y_test for l in ls]), \n",
    "    fp=open(\"{}/testing_distribution.json\".format(direc), 'w'),\n",
    "    indent=4, sort_keys=True\n",
    ")\n",
    "\n",
    "X_train = annotation_ex.transform(X_train_ppis)\n",
    "X_test = annotation_ex.transform(X_test_ppis)\n",
    "y_train = mlb.transform(y_train)\n",
    "y_test = mlb.transform(y_test)\n",
    "\n",
    "del annotation_ex\n",
    "del uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:52:32] INFO: Setting up preliminaries and the statistics arrays\n",
      "[08-26-2017 05:52:32] INFO: Found classes activation, binding/association, inhibition, carboxylation, sulfation, methylation, proteolytic-cleavage, phosphorylation, dephosphorylation, sumoylation, ubiquitination, prenylation, state-change, myristoylation, deacetylation, acetylation, dissociation, glycosylation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Setting up preliminaries and the statistics arrays\")\n",
    "logging.info(\"Found classes {}\".format(', '.join(mlb.classes)))\n",
    "n_classes = len(mlb.classes)\n",
    "seeds = range(n_iter)\n",
    "top_features = {l:{i:{j:[] for j in range(n_splits)} for i in range(n_iter)} for l in labels}\n",
    "params = get_parameter_distribution_form_model(model)\n",
    "\n",
    "binary_scoring_funcs = [\n",
    "    ('Binary F1', f1_score) , \n",
    "    ('Precision', precision_score), \n",
    "    ('Recall', recall_score),\n",
    "    ('Specificity', specificity),\n",
    "    ('FDR', fdr_score)\n",
    "]\n",
    "multilabel_scores_funcs = [\n",
    "    ('Label Ranking Loss', label_ranking_loss), \n",
    "    ('Label Ranking Average Precision', label_ranking_average_precision_score), \n",
    "    ('Macro (weighted) F1', f1_score), \n",
    "    ('Macro (un-weighted) F1', f1_score)\n",
    "]\n",
    "n_scorers = len(binary_scoring_funcs)\n",
    "n_ml_scorers = len(multilabel_scores_funcs)\n",
    "\n",
    "# 2: position 0 is for validation, position 1 is for testing\n",
    "binary_statistics = np.zeros((n_iter, n_splits, n_classes, 2, n_scorers))\n",
    "multilabel_statistics = np.zeros((n_iter, n_splits, 2, n_ml_scorers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:52:33] INFO: Fitting bootstrap iteration 1.\n",
      "[08-26-2017 05:52:36] INFO: Fitting fold iteration 1.\n",
      "[08-26-2017 05:52:36] INFO: Fitting label activation.\n",
      "[08-26-2017 05:52:36] INFO: Preparing data.\n",
      "[08-26-2017 05:52:42] INFO: Fitting classifier.\n",
      "[08-26-2017 05:52:57] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:52:57] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:52:57] INFO: Fitting label binding/association.\n",
      "[08-26-2017 05:52:57] INFO: Preparing data.\n",
      "[08-26-2017 05:53:04] INFO: Fitting classifier.\n",
      "[08-26-2017 05:53:10] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:53:10] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:53:10] INFO: Fitting label inhibition.\n",
      "[08-26-2017 05:53:10] INFO: Preparing data.\n",
      "[08-26-2017 05:53:17] INFO: Fitting classifier.\n",
      "[08-26-2017 05:53:26] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:53:26] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:53:26] INFO: Fitting label carboxylation.\n",
      "[08-26-2017 05:53:26] INFO: Preparing data.\n",
      "[08-26-2017 05:53:32] INFO: Fitting classifier.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[08-26-2017 05:53:35] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:53:35] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:53:35] INFO: Fitting label sulfation.\n",
      "[08-26-2017 05:53:35] INFO: Preparing data.\n",
      "[08-26-2017 05:53:42] INFO: Fitting classifier.\n",
      "[08-26-2017 05:53:44] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:53:44] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:53:44] INFO: Fitting label methylation.\n",
      "[08-26-2017 05:53:44] INFO: Preparing data.\n",
      "[08-26-2017 05:53:51] INFO: Fitting classifier.\n",
      "[08-26-2017 05:53:53] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:53:54] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:53:54] INFO: Fitting label proteolytic-cleavage.\n",
      "[08-26-2017 05:53:54] INFO: Preparing data.\n",
      "[08-26-2017 05:54:00] INFO: Fitting classifier.\n",
      "[08-26-2017 05:54:04] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:54:04] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:54:04] INFO: Fitting label phosphorylation.\n",
      "[08-26-2017 05:54:04] INFO: Preparing data.\n",
      "[08-26-2017 05:54:11] INFO: Fitting classifier.\n",
      "[08-26-2017 05:54:28] INFO: Computing fold label binary performance.\n",
      "[08-26-2017 05:54:28] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:54:28] INFO: Fitting label dephosphorylation.\n",
      "[08-26-2017 05:54:28] INFO: Preparing data.\n",
      "[08-26-2017 05:54:35] INFO: Fitting classifier.\n",
      "[08-26-2017 05:54:38] INFO: Computing fold label binary performance.\n",
      "[08-26-2017 05:54:38] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:54:38] INFO: Fitting label sumoylation.\n",
      "[08-26-2017 05:54:38] INFO: Preparing data.\n",
      "[08-26-2017 05:54:44] INFO: Fitting classifier.\n",
      "[08-26-2017 05:54:47] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:54:47] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:54:47] INFO: Fitting label ubiquitination.\n",
      "[08-26-2017 05:54:47] INFO: Preparing data.\n",
      "[08-26-2017 05:54:54] INFO: Fitting classifier.\n",
      "[08-26-2017 05:54:57] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:54:57] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:54:57] INFO: Fitting label prenylation.\n",
      "[08-26-2017 05:54:57] INFO: Preparing data.\n",
      "[08-26-2017 05:55:03] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:06] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:55:06] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:06] INFO: Fitting label state-change.\n",
      "[08-26-2017 05:55:06] INFO: Preparing data.\n",
      "[08-26-2017 05:55:13] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:16] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:55:16] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:16] INFO: Fitting label myristoylation.\n",
      "[08-26-2017 05:55:16] INFO: Preparing data.\n",
      "[08-26-2017 05:55:23] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:26] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:55:26] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:26] INFO: Fitting label deacetylation.\n",
      "[08-26-2017 05:55:26] INFO: Preparing data.\n",
      "[08-26-2017 05:55:33] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:36] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:55:36] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:36] INFO: Fitting label acetylation.\n",
      "[08-26-2017 05:55:36] INFO: Preparing data.\n",
      "[08-26-2017 05:55:42] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:45] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:55:45] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:45] INFO: Fitting label dissociation.\n",
      "[08-26-2017 05:55:45] INFO: Preparing data.\n",
      "[08-26-2017 05:55:52] INFO: Fitting classifier.\n",
      "[08-26-2017 05:55:57] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:55:57] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:55:57] INFO: Fitting label glycosylation.\n",
      "[08-26-2017 05:55:57] INFO: Preparing data.\n",
      "[08-26-2017 05:56:03] INFO: Fitting classifier.\n",
      "[08-26-2017 05:56:06] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:56:06] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:56:06] INFO: Computing fold mult-label performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:56:10] INFO: Fitting fold iteration 2.\n",
      "[08-26-2017 05:56:10] INFO: Fitting label activation.\n",
      "[08-26-2017 05:56:10] INFO: Preparing data.\n",
      "[08-26-2017 05:56:17] INFO: Fitting classifier.\n",
      "[08-26-2017 05:56:37] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:56:37] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:56:37] INFO: Fitting label binding/association.\n",
      "[08-26-2017 05:56:37] INFO: Preparing data.\n",
      "[08-26-2017 05:56:45] INFO: Fitting classifier.\n",
      "[08-26-2017 05:56:50] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:56:50] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:56:50] INFO: Fitting label inhibition.\n",
      "[08-26-2017 05:56:50] INFO: Preparing data.\n",
      "[08-26-2017 05:56:57] INFO: Fitting classifier.\n",
      "[08-26-2017 05:57:06] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:57:07] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:57:07] INFO: Fitting label carboxylation.\n",
      "[08-26-2017 05:57:07] INFO: Preparing data.\n",
      "[08-26-2017 05:57:13] INFO: Fitting classifier.\n",
      "[08-26-2017 05:57:16] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:57:16] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:57:16] INFO: Fitting label sulfation.\n",
      "[08-26-2017 05:57:16] INFO: Preparing data.\n",
      "[08-26-2017 05:57:22] INFO: Fitting classifier.\n",
      "[08-26-2017 05:57:25] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:57:25] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:57:25] INFO: Fitting label methylation.\n",
      "[08-26-2017 05:57:25] INFO: Preparing data.\n",
      "[08-26-2017 05:57:32] INFO: Fitting classifier.\n",
      "[08-26-2017 05:57:34] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:57:34] INFO: Computing top label features for fold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:57:34] INFO: Fitting label proteolytic-cleavage.\n",
      "[08-26-2017 05:57:34] INFO: Preparing data.\n",
      "[08-26-2017 05:57:41] INFO: Fitting classifier.\n",
      "[08-26-2017 05:57:45] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:57:45] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:57:45] INFO: Fitting label phosphorylation.\n",
      "[08-26-2017 05:57:45] INFO: Preparing data.\n",
      "[08-26-2017 05:57:52] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:08] INFO: Computing fold label binary performance.\n",
      "[08-26-2017 05:58:08] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:08] INFO: Fitting label dephosphorylation.\n",
      "[08-26-2017 05:58:08] INFO: Preparing data.\n",
      "[08-26-2017 05:58:15] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:18] INFO: Computing fold label binary performance.\n",
      "[08-26-2017 05:58:18] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:18] INFO: Fitting label sumoylation.\n",
      "[08-26-2017 05:58:18] INFO: Preparing data.\n",
      "[08-26-2017 05:58:25] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:27] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:58:27] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:28] INFO: Fitting label ubiquitination.\n",
      "[08-26-2017 05:58:28] INFO: Preparing data.\n",
      "[08-26-2017 05:58:34] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:37] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:58:37] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:37] INFO: Fitting label prenylation.\n",
      "[08-26-2017 05:58:37] INFO: Preparing data.\n",
      "[08-26-2017 05:58:44] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:47] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:58:47] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:47] INFO: Fitting label state-change.\n",
      "[08-26-2017 05:58:47] INFO: Preparing data.\n",
      "[08-26-2017 05:58:53] INFO: Fitting classifier.\n",
      "[08-26-2017 05:58:56] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:58:56] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:58:56] INFO: Fitting label myristoylation.\n",
      "[08-26-2017 05:58:56] INFO: Preparing data.\n",
      "[08-26-2017 05:59:03] INFO: Fitting classifier.\n",
      "[08-26-2017 05:59:05] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:59:06] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:59:06] INFO: Fitting label deacetylation.\n",
      "[08-26-2017 05:59:06] INFO: Preparing data.\n",
      "[08-26-2017 05:59:12] INFO: Fitting classifier.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[08-26-2017 05:59:16] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:59:16] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:59:16] INFO: Fitting label acetylation.\n",
      "[08-26-2017 05:59:16] INFO: Preparing data.\n",
      "[08-26-2017 05:59:22] INFO: Fitting classifier.\n",
      "[08-26-2017 05:59:26] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:59:26] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:59:26] INFO: Fitting label dissociation.\n",
      "[08-26-2017 05:59:26] INFO: Preparing data.\n",
      "[08-26-2017 05:59:32] INFO: Fitting classifier.\n",
      "[08-26-2017 05:59:36] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "[08-26-2017 05:59:36] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:59:36] INFO: Fitting label glycosylation.\n",
      "[08-26-2017 05:59:36] INFO: Preparing data.\n",
      "[08-26-2017 05:59:42] INFO: Fitting classifier.\n",
      "[08-26-2017 05:59:45] INFO: Computing fold label binary performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\pyppi-0.1-py3.5.egg\\pyppi\\model_selection\\scoring.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "[08-26-2017 05:59:45] INFO: Computing top label features for fold.\n",
      "[08-26-2017 05:59:45] INFO: Computing fold mult-label performance.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\pyppi\\lib\\site-packages\\scikit_learn-0.18.2-py3.5-win-amd64.egg\\sklearn\\metrics\\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for bs_iter in range(n_iter):\n",
    "    logging.info(\"Fitting bootstrap iteration {}.\".format(bs_iter + 1))\n",
    "    cv = IterativeStratifiedKFold(n_splits=n_splits, random_state=seeds[bs_iter])\n",
    "    \n",
    "    for fold_iter, (train_idx, validation_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "        logging.info(\"Fitting fold iteration {}.\".format(fold_iter + 1))\n",
    "        y_valid_f_pred = []\n",
    "        y_test_f_pred = []\n",
    "        y_valid_f_proba = []\n",
    "        y_test_f_proba = []\n",
    "        \n",
    "        for label in sorted(labels):\n",
    "            label_idx = labels.index(label)\n",
    "            logging.info(\"Fitting label {}.\".format(label))\n",
    "            \n",
    "            # Prepare all training and testing data\n",
    "            logging.info(\"Preparing data.\")\n",
    "            vectorizer = CountVectorizer(binary=False)\n",
    "            vectorizer.fit(X_train[train_idx])\n",
    "\n",
    "            X_train_l = vectorizer.transform(X_train[train_idx])\n",
    "            y_train_l = y_train[train_idx, label_idx]\n",
    "        \n",
    "            X_valid_l = vectorizer.transform(X_train[validation_idx])\n",
    "            y_valid_l = y_train[validation_idx, label_idx]\n",
    "\n",
    "            X_test_l = vectorizer.transform(X_test)\n",
    "            y_test_l = y_test[:, label_idx]\n",
    "            \n",
    "            # Build and fit classifier\n",
    "            logging.info(\"Fitting classifier.\")\n",
    "            base_est = make_classifier(\n",
    "                algorithm=model, \n",
    "                random_state=0\n",
    "            )\n",
    "            clf = RandomizedSearchCV(\n",
    "                estimator=base_est,\n",
    "                scoring='f1', \n",
    "                error_score=0,\n",
    "                cv=3, \n",
    "                n_iter=hyperparam_iter, \n",
    "                n_jobs=n_jobs, \n",
    "                refit=True, \n",
    "                random_state=0, \n",
    "                param_distributions=params,\n",
    "            )\n",
    "            try:\n",
    "                clf.fit(X_train_l, y_train_l)\n",
    "            except TypeError:\n",
    "                logger.info(\"Error fitting sparse input. Converting to dense input.\")\n",
    "                X_train_l = X_train_l.todense()\n",
    "                X_valid_l = X_valid_l.todense()\n",
    "                X_test_l = X_test_l.todense()\n",
    "                clf.fit(X_train_l, y_train_l)\n",
    "            \n",
    "            # Validation scores in binary and probability format\n",
    "            y_valid_l_pred = clf.predict(X_valid_l)\n",
    "            y_valid_l_proba = clf.predict_proba(X_valid_l)\n",
    "            \n",
    "            # Held-out testing scores in binary and probability format\n",
    "            y_test_l_pred = clf.predict(X_test_l)\n",
    "            y_test_l_proba = clf.predict_proba(X_test_l)\n",
    "            \n",
    "            # Store these per label results in a list which we will\n",
    "            # later use to stack into a multi-label array.\n",
    "            y_valid_f_pred.append([[x] for x in y_valid_l_pred])\n",
    "            y_valid_f_proba.append([[x[1]] for x in y_valid_l_proba])\n",
    "            \n",
    "            y_test_f_pred.append([[x] for x in y_test_l_pred])\n",
    "            y_test_f_proba.append([[x[1]] for x in y_test_l_proba])\n",
    "            \n",
    "            # Perform scoring on the validation set and the external testing set.\n",
    "            logging.info(\"Computing fold label binary performance.\")\n",
    "            for func_idx, (func_name, func) in enumerate(binary_scoring_funcs):\n",
    "                if func_name in ['Specificity', 'FDR']:\n",
    "                    scores_v = func(y_valid_l, y_valid_l_pred)\n",
    "                    scores_t = func(y_test_l, y_test_l_pred)\n",
    "                else:\n",
    "                    scores_v = func(y_valid_l, y_valid_l_pred, average='binary')\n",
    "                    scores_t = func(y_test_l, y_test_l_pred, average='binary')\n",
    "                binary_statistics[bs_iter, fold_iter, label_idx, 0, func_idx] = scores_v\n",
    "                binary_statistics[bs_iter, fold_iter, label_idx, 1, func_idx] = scores_t\n",
    "                \n",
    "            logging.info(\"Computing top label features for fold.\")\n",
    "            # Get the top 20 features for this labels's run.\n",
    "            top_n = top_n_features(\n",
    "                clf=clf,\n",
    "                go_dag=go_dag,\n",
    "                ipr_map=ipr_map,\n",
    "                pfam_map=pfam_map,\n",
    "                n=get_top_n, \n",
    "                absolute=abs_weights, \n",
    "                vectorizer=vectorizer\n",
    "            )\n",
    "            top_features[label][bs_iter][fold_iter].extend(top_n)\n",
    "        \n",
    "        logging.info(\"Computing fold mult-label performance.\")\n",
    "        # True scores in multi-label indicator format\n",
    "        y_valid_f = y_train[validation_idx]\n",
    "        y_test_f = y_test\n",
    "        \n",
    "        # Validation scores in multi-label indicator format\n",
    "        y_valid_f_pred = np.hstack(y_valid_f_pred)\n",
    "        y_valid_f_proba = np.hstack(y_valid_f_proba)\n",
    "        \n",
    "        # Testing scores in multi-label probability format\n",
    "        y_test_f_pred = np.hstack(y_test_f_pred)\n",
    "        y_test_f_proba = np.hstack(y_test_f_proba)\n",
    "        \n",
    "        for func_idx, (func_name, func) in enumerate(multilabel_scores_funcs):\n",
    "            if func_name == 'Macro (weighted) F1':\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred, average='weighted')\n",
    "                scores_t = func(y_test_f, y_test_f_pred, average='weighted')\n",
    "            elif func_name == 'Macro (un-weighted) F1':\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred, average='macro')\n",
    "                scores_t = func(y_test_f, y_test_f_pred, average='macro')\n",
    "            elif func_name == 'Label Ranking Average Precision':\n",
    "                scores_v = func(y_valid_f, y_valid_f_proba)\n",
    "                scores_t = func(y_test_f, y_test_f_proba)\n",
    "            else:\n",
    "                scores_v = func(y_valid_f, y_valid_f_pred)\n",
    "                scores_t = func(y_test_f, y_test_f_pred)\n",
    "                \n",
    "            multilabel_statistics[bs_iter, fold_iter, 0, func_idx] = scores_v\n",
    "            multilabel_statistics[bs_iter, fold_iter, 1, func_idx] = scores_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:59:49] INFO: Writing statistics to file.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Writing statistics to file.\")\n",
    "func_names = [n for n, _ in binary_scoring_funcs]\n",
    "iterables = [range(n_iter), range(n_splits), mlb.classes, [\"validation\", \"holdout\"], func_names]\n",
    "names=['bootstrap iteration', 'fold iteration', 'labels', 'condition', 'score function']\n",
    "index = pd.MultiIndex.from_product(iterables, names=names)\n",
    "binary_df = pd.DataFrame(binary_statistics.ravel(), index=index)[0]\n",
    "binary_df.to_csv('{}/{}'.format(direc, 'binary_stats.csv'), sep=',')\n",
    "np.save('{}/{}'.format(direc, 'binary_stats.np'), binary_statistics, allow_pickle=False)\n",
    "\n",
    "func_names = [n for n, _ in multilabel_scores_funcs]\n",
    "iterables = [range(n_iter), range(n_splits), [\"validation\", \"holdout\"], func_names]\n",
    "names=['bootstrap iteration', 'fold iteration', 'condition', 'score function']\n",
    "index = pd.MultiIndex.from_product(iterables, names=names)\n",
    "multilabel_df = pd.DataFrame(multilabel_statistics.ravel(), index=index)[0]\n",
    "multilabel_df.to_csv('{}/{}'.format(direc, 'multilabel_stats.csv'), sep=',')\n",
    "np.save('{}/{}'.format(direc, 'multilabel_stats.np'), multilabel_statistics, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08-26-2017 05:59:50] INFO: Writing top features to file.\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Writing label order.\")\n",
    "with open(\"{}/{}\".format(direc, \"label_order.csv\"), 'wt') as fp:\n",
    "    fp.write(\",\".join(sorted(labels)))\n",
    "\n",
    "logging.info(\"Writing top features to file.\")\n",
    "with open('{}/{}'.format(direc, 'top_features.json'), 'wt') as fp:\n",
    "    json.dump(top_features, fp, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyppi]",
   "language": "python",
   "name": "conda-env-pyppi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
